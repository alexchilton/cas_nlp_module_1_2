{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fcd59bb",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"><strong>Machine translation</strong></h1>\n",
    "\n",
    "Machine translation (MT) is the study of how to use computers to translate from one language into another. In terms of methodologies MT mainly falls in two categories: rule-based methods and corpus-based-methods.  \n",
    "\n",
    "In this short notebook a dataset containing japanese and english text will be loaded and prepared for a machine translation task.  \n",
    "The preparation will limit itself to the extraction of the sentence pair and the splitting into train and test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de185526",
   "metadata": {},
   "source": [
    "# Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8a6c482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021eda5b",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "788c26dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laran\\.cache\\kagglehub\\datasets\\team-ai\\japaneseenglish-bilingual-corpus\\versions\\3\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "root=Path(kagglehub.dataset_download(\"team-ai/japaneseenglish-bilingual-corpus\"))\n",
    "print(root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "483c0b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WindowsPath('C:/Users/laran/.cache/kagglehub/datasets/team-ai/japaneseenglish-bilingual-corpus/versions/3/BDS00389.xml'),\n",
      " WindowsPath('C:/Users/laran/.cache/kagglehub/datasets/team-ai/japaneseenglish-bilingual-corpus/versions/3/fonts-japanese-gothic.ttf'),\n",
      " WindowsPath('C:/Users/laran/.cache/kagglehub/datasets/team-ai/japaneseenglish-bilingual-corpus/versions/3/kyoto_lexicon.csv'),\n",
      " WindowsPath('C:/Users/laran/.cache/kagglehub/datasets/team-ai/japaneseenglish-bilingual-corpus/versions/3/readme.pdf'),\n",
      " WindowsPath('C:/Users/laran/.cache/kagglehub/datasets/team-ai/japaneseenglish-bilingual-corpus/versions/3/wiki_corpus_2.01/BDS/BDS00001.xml'),\n",
      " WindowsPath('C:/Users/laran/.cache/kagglehub/datasets/team-ai/japaneseenglish-bilingual-corpus/versions/3/wiki_corpus_2.01/BDS/BDS00002.xml'),\n",
      " WindowsPath('C:/Users/laran/.cache/kagglehub/datasets/team-ai/japaneseenglish-bilingual-corpus/versions/3/wiki_corpus_2.01/BDS/BDS00003.xml'),\n",
      " WindowsPath('C:/Users/laran/.cache/kagglehub/datasets/team-ai/japaneseenglish-bilingual-corpus/versions/3/wiki_corpus_2.01/BDS/BDS00004.xml'),\n",
      " WindowsPath('C:/Users/laran/.cache/kagglehub/datasets/team-ai/japaneseenglish-bilingual-corpus/versions/3/wiki_corpus_2.01/BDS/BDS00005.xml'),\n",
      " WindowsPath('C:/Users/laran/.cache/kagglehub/datasets/team-ai/japaneseenglish-bilingual-corpus/versions/3/wiki_corpus_2.01/BDS/BDS00006.xml')]\n"
     ]
    }
   ],
   "source": [
    "files=sorted(p for p in root.rglob(\"*\") if p.is_file())\n",
    "pprint(files[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dec28ad",
   "metadata": {},
   "source": [
    "Files are mostly XML files, to be able to use the parallel english / japanese text the XML files must be parsed first: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32171a0a",
   "metadata": {},
   "source": [
    "### 1) check the tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda9756b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "art {'orl': 'ja', 'trl': 'en'}\n"
     ]
    }
   ],
   "source": [
    "base = root / \"wiki_corpus_2.01\" / \"BDS\"\n",
    "xml_file = sorted(base.glob(\"BDS*.xml\"))[0]\n",
    "root = ET.parse(xml_file).getroot()\n",
    "\n",
    "for el in root.iter():\n",
    "    print(el.tag, el.attrib)\n",
    "    # Stop early to avoid printing everything\n",
    "    if len(list(el)) > 0:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b02780",
   "metadata": {},
   "source": [
    "Tags are 'ja' for japanese and 'en' for english.  \n",
    "The structure will be further explored to properly extract japanese - english pairs\n",
    "\n",
    "### 2. inspect the structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "366a9fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level-1 child tags: Counter({'sec': 6, 'par': 5, 'inf': 1, 'tit': 1, 'copyright': 1})\n",
      "\n",
      "<inf> children: Counter()\n",
      "  sample leaf <inf>: jawiki-20080607-pages-articles.xml\n",
      "\n",
      "<tit> children: Counter({'e': 3, 'cmt': 3, 'j': 1})\n",
      "  sample leaf <j>: 雪舟\n",
      "\n",
      "<par> children: Counter({'sen': 2})\n",
      "  sample leaf <j>: 雪舟（せっしゅう、1420年（応永27年） - 1506年（永正3年））は号で、15世紀後半室町時代に活躍した水墨画家・禅僧で、画聖とも称えられる。\n",
      "\n",
      "<sec> children: Counter({'par': 3, 'tit': 1})\n",
      "  sample leaf <j>: 生涯\n",
      "\n",
      "<copyright> children: Counter()\n",
      "  sample leaf <copyright>: copyright (c) 2010 Avanzare(id:34657), Kanejan(id:78613), Tommy6(id:51773), Nnh(id:474), Suguri F(id:11127), FREEZA(id:6\n"
     ]
    }
   ],
   "source": [
    "assert root.tag.endswith(\"art\") and root.attrib.get(\"orl\")==\"ja\" and root.attrib.get(\"trl\")==\"en\"\n",
    "\n",
    "# List first-level children under <art>\n",
    "lvl1 = [c.tag for c in root]\n",
    "\n",
    "print(\"Level-1 child tags:\", Counter(lvl1))\n",
    "\n",
    "# Peek deeper: for each distinct lvl1 tag, show its distinct children and sample text\n",
    "def strip_ns(tag): \n",
    "    return tag.split(\"}\",1)[1] if \"}\" in tag else tag\n",
    "\n",
    "seen = set()\n",
    "for c in root:\n",
    "    t = strip_ns(c.tag)\n",
    "    if t in seen: \n",
    "        continue\n",
    "    seen.add(t)\n",
    "    sub = [strip_ns(x.tag) for x in list(c)]\n",
    "    print(f\"\\n<{t}> children:\", Counter(sub))\n",
    "    # print a couple of leaf texts\n",
    "    for leaf in c.iter():\n",
    "        if len(list(leaf))==0 and (leaf.text or \"\").strip():\n",
    "            txt = leaf.text.strip().replace(\"\\n\",\" \")[:120]\n",
    "            print(f\"  sample leaf <{strip_ns(leaf.tag)}>: {txt}\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b886d636",
   "metadata": {},
   "source": [
    "**interpretation**: \n",
    "- Root is: <art orl=\"ja\" trl=\"en\">\n",
    "- frequent childrens are: sec, par, tit, inf, copyright\n",
    "- language tags are: < j > for japanese and < e > for english \n",
    "\n",
    "\n",
    "With these informations we can built the extractor. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04eb13a",
   "metadata": {},
   "source": [
    "### 3) Built the extractor and the paired dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce48e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = root / \"wiki_corpus_2.01\" / \"BDS\"\n",
    "base.glob(\"BDS*.xml\")\n",
    "\n",
    "TAG_PAIR      = None         # No wrapper available\n",
    "TAG_ORIGINAL  = \"j\"          # japanese tag\n",
    "TAG_TRANSL    = \"e\"          # english tag\n",
    "\n",
    "def strip_ns(tag):\n",
    "    return tag.split(\"}\",1)[1] if \"}\" in tag else tag\n",
    "\n",
    "def text_or_none(el):\n",
    "    return (el.text or \"\").strip() if el is not None and el.text else None\n",
    "\n",
    "pairs = []\n",
    "for xf in sorted(base.glob(\"BDS*.xml\")):\n",
    "    root = ET.parse(xf).getroot()\n",
    "\n",
    "    if TAG_PAIR:\n",
    "        # option 1 --> if I have the wrapper (not our case as TAG_PAIR=None)\n",
    "        for node in root.findall(f\".//{TAG_PAIR}\"):\n",
    "            ja = text_or_none(node.find(TAG_ORIGINAL))\n",
    "            en = text_or_none(node.find(TAG_TRANSL))\n",
    "            if ja and en:\n",
    "                pairs.append((ja, en))\n",
    "    else:\n",
    "        # option 2 --> called in case we have no explicit wrapper (our case)\n",
    "        for node in root.iter():\n",
    "            children = list(node)\n",
    "            if not children: \n",
    "                continue\n",
    "            tagmap = {strip_ns(c.tag).lower(): c for c in children}\n",
    "            if TAG_ORIGINAL.lower() in tagmap and TAG_TRANSL.lower() in tagmap:\n",
    "                ja = text_or_none(tagmap[TAG_ORIGINAL.lower()])\n",
    "                en = text_or_none(tagmap[TAG_TRANSL.lower()])\n",
    "                if ja and en:\n",
    "                    pairs.append((ja, en))\n",
    "\n",
    "df = pd.DataFrame(pairs, columns=[\"ja\", \"en\"]).dropna()   # dataframe and cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f6dc56",
   "metadata": {},
   "source": [
    "### 4) inspect the newly created dataframe.  \n",
    "\n",
    "Does it make sense? were the tag correctly extracted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc14da3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ja</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>雪舟</td>\n",
       "      <td>Sesshu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>雪舟（せっしゅう、1420年（応永27年） - 1506年（永正3年））は号で、15世紀後半...</td>\n",
       "      <td>Known as Sesshu (1420 - 1506), he was an ink p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>日本の水墨画を一変させた。</td>\n",
       "      <td>He revolutionized the Japanese ink painting.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>諱は「等楊（とうよう）」、もしくは「拙宗（せっしゅう）」と号した。</td>\n",
       "      <td>He was given the posthumous name \"Toyo\" or \"Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>備中国に生まれ、京都・相国寺に入ってから周防国に移る。</td>\n",
       "      <td>Born in Bicchu Province, he moved to Suo Provi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  ja  \\\n",
       "0                                                 雪舟   \n",
       "1  雪舟（せっしゅう、1420年（応永27年） - 1506年（永正3年））は号で、15世紀後半...   \n",
       "2                                      日本の水墨画を一変させた。   \n",
       "3                  諱は「等楊（とうよう）」、もしくは「拙宗（せっしゅう）」と号した。   \n",
       "4                        備中国に生まれ、京都・相国寺に入ってから周防国に移る。   \n",
       "\n",
       "                                                  en  \n",
       "0                                             Sesshu  \n",
       "1  Known as Sesshu (1420 - 1506), he was an ink p...  \n",
       "2       He revolutionized the Japanese ink painting.  \n",
       "3  He was given the posthumous name \"Toyo\" or \"Se...  \n",
       "4  Born in Bicchu Province, he moved to Suo Provi...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a1c4bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs: 28384\n"
     ]
    }
   ],
   "source": [
    "print(\"Total pairs:\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6b79d0",
   "metadata": {},
   "source": [
    "### 5) Prepare the data for machine translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5018480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['ja']   # original \n",
    "y = df['en']   # translated\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da77c98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Overview----\n",
      "\n",
      "Training set size: 22707 entries\n",
      "Testing set size: 5677 entries\n"
     ]
    }
   ],
   "source": [
    "# checks\n",
    "print(f\"----Overview----\")\n",
    "print(\"\")\n",
    "print(f\"Training set size: {len(X_train)} entries\")\n",
    "print(f\"Testing set size: {len(X_test)} entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66159d9",
   "metadata": {},
   "source": [
    "## Vectorization & embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c658c71",
   "metadata": {},
   "source": [
    "Due to the nature of the dataset the vectorization through a CountVectorizer would not be relevant.  \n",
    "For the MT task will be attempted a sequence tokenization and a seq2seq model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ec55bd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLPvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
