{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Transformer Model for Language Translation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T12:49:45.542652Z",
     "start_time": "2025-08-21T12:49:45.514172Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "    <meta charset=\"UTF-8\">\n",
       "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
       "    <title>Evolution of Machine Translation</title>\n",
       "    <style>\n",
       "        body {\n",
       "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
       "            margin: 0;\n",
       "            padding: 20px;\n",
       "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
       "            color: #333;\n",
       "        }\n",
       "\n",
       "        .container {\n",
       "            max-width: 1400px;\n",
       "            margin: 0 auto;\n",
       "        }\n",
       "\n",
       "        h1 {\n",
       "            text-align: center;\n",
       "            color: white;\n",
       "            font-size: 2.5em;\n",
       "            margin-bottom: 40px;\n",
       "            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);\n",
       "        }\n",
       "\n",
       "        .timeline {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            gap: 40px;\n",
       "        }\n",
       "\n",
       "        .era {\n",
       "            background: white;\n",
       "            border-radius: 20px;\n",
       "            padding: 30px;\n",
       "            box-shadow: 0 10px 30px rgba(0,0,0,0.1);\n",
       "            position: relative;\n",
       "            margin-left: 50px;\n",
       "        }\n",
       "\n",
       "        .era::before {\n",
       "            content: '';\n",
       "            position: absolute;\n",
       "            left: -50px;\n",
       "            top: 30px;\n",
       "            width: 40px;\n",
       "            height: 40px;\n",
       "            border-radius: 50%;\n",
       "            background: linear-gradient(45deg, #667eea, #764ba2);\n",
       "            color: white;\n",
       "            display: flex;\n",
       "            align-items: center;\n",
       "            justify-content: center;\n",
       "            font-weight: bold;\n",
       "            z-index: 2;\n",
       "        }\n",
       "\n",
       "        .timeline-line {\n",
       "            position: absolute;\n",
       "            left: -30px;\n",
       "            top: 0;\n",
       "            bottom: 0;\n",
       "            width: 4px;\n",
       "            background: linear-gradient(to bottom, #667eea, #764ba2);\n",
       "            z-index: 1;\n",
       "        }\n",
       "\n",
       "        .era-header {\n",
       "            display: flex;\n",
       "            justify-content: space-between;\n",
       "            align-items: center;\n",
       "            margin-bottom: 20px;\n",
       "            padding-bottom: 15px;\n",
       "            border-bottom: 3px solid #e2e8f0;\n",
       "        }\n",
       "\n",
       "        .era-title {\n",
       "            font-size: 1.8em;\n",
       "            font-weight: bold;\n",
       "            color: #2d3748;\n",
       "        }\n",
       "\n",
       "        .era-period {\n",
       "            background: linear-gradient(45deg, #667eea, #764ba2);\n",
       "            color: white;\n",
       "            padding: 8px 16px;\n",
       "            border-radius: 20px;\n",
       "            font-weight: bold;\n",
       "        }\n",
       "\n",
       "        .architecture-diagram {\n",
       "            background: #f8f9fa;\n",
       "            border: 2px solid #e2e8f0;\n",
       "            border-radius: 15px;\n",
       "            padding: 25px;\n",
       "            margin: 20px 0;\n",
       "            text-align: center;\n",
       "        }\n",
       "\n",
       "        .example {\n",
       "            background: #e3f2fd;\n",
       "            border-left: 4px solid #2196f3;\n",
       "            padding: 15px;\n",
       "            margin: 15px 0;\n",
       "            border-radius: 0 10px 10px 0;\n",
       "        }\n",
       "\n",
       "        .pros-cons {\n",
       "            display: grid;\n",
       "            grid-template-columns: 1fr 1fr;\n",
       "            gap: 20px;\n",
       "            margin: 20px 0;\n",
       "        }\n",
       "\n",
       "        .pros {\n",
       "            background: #e8f5e8;\n",
       "            border: 2px solid #4caf50;\n",
       "            border-radius: 10px;\n",
       "            padding: 15px;\n",
       "        }\n",
       "\n",
       "        .cons {\n",
       "            background: #ffebee;\n",
       "            border: 2px solid #f44336;\n",
       "            border-radius: 10px;\n",
       "            padding: 15px;\n",
       "        }\n",
       "\n",
       "        /* SMT Specific */\n",
       "        .phrase-table {\n",
       "            display: grid;\n",
       "            grid-template-columns: repeat(3, 1fr);\n",
       "            gap: 10px;\n",
       "            margin: 20px 0;\n",
       "        }\n",
       "\n",
       "        .phrase-pair {\n",
       "            background: #fff3e0;\n",
       "            border: 2px solid #ff9800;\n",
       "            border-radius: 8px;\n",
       "            padding: 10px;\n",
       "            text-align: center;\n",
       "            font-size: 14px;\n",
       "        }\n",
       "\n",
       "        /* Neural Network Components */\n",
       "        .nn-component {\n",
       "            display: inline-block;\n",
       "            background: linear-gradient(45deg, #ff6b6b, #ee5a52);\n",
       "            color: white;\n",
       "            padding: 15px 20px;\n",
       "            border-radius: 12px;\n",
       "            margin: 5px;\n",
       "            font-weight: bold;\n",
       "            min-width: 80px;\n",
       "            text-align: center;\n",
       "        }\n",
       "\n",
       "        .nn-component.encoder {\n",
       "            background: linear-gradient(45deg, #4ecdc4, #44a08d);\n",
       "        }\n",
       "\n",
       "        .nn-component.decoder {\n",
       "            background: linear-gradient(45deg, #a8e6cf, #7fcdcd);\n",
       "        }\n",
       "\n",
       "        .nn-component.attention {\n",
       "            background: linear-gradient(45deg, #ffd93d, #ff9f1a);\n",
       "        }\n",
       "\n",
       "        .nn-component.transformer {\n",
       "            background: linear-gradient(45deg, #667eea, #764ba2);\n",
       "        }\n",
       "\n",
       "        .arrow {\n",
       "            display: inline-block;\n",
       "            margin: 0 10px;\n",
       "            font-size: 20px;\n",
       "            color: #4a5568;\n",
       "        }\n",
       "\n",
       "        .flow-diagram {\n",
       "            display: flex;\n",
       "            align-items: center;\n",
       "            justify-content: center;\n",
       "            flex-wrap: wrap;\n",
       "            margin: 20px 0;\n",
       "        }\n",
       "\n",
       "        .attention-matrix {\n",
       "            display: grid;\n",
       "            grid-template-columns: repeat(4, 40px);\n",
       "            gap: 2px;\n",
       "            margin: 20px auto;\n",
       "            width: fit-content;\n",
       "        }\n",
       "\n",
       "        .attention-cell {\n",
       "            width: 40px;\n",
       "            height: 40px;\n",
       "            border-radius: 4px;\n",
       "            display: flex;\n",
       "            align-items: center;\n",
       "            justify-content: center;\n",
       "            font-size: 12px;\n",
       "            color: white;\n",
       "            font-weight: bold;\n",
       "        }\n",
       "\n",
       "        .quality-meter {\n",
       "            display: flex;\n",
       "            align-items: center;\n",
       "            margin: 15px 0;\n",
       "        }\n",
       "\n",
       "        .quality-bar {\n",
       "            width: 200px;\n",
       "            height: 20px;\n",
       "            background: #e2e8f0;\n",
       "            border-radius: 10px;\n",
       "            margin: 0 15px;\n",
       "            overflow: hidden;\n",
       "        }\n",
       "\n",
       "        .quality-fill {\n",
       "            height: 100%;\n",
       "            border-radius: 10px;\n",
       "            transition: width 0.5s ease;\n",
       "        }\n",
       "\n",
       "        .interactive-btn {\n",
       "            background: linear-gradient(45deg, #667eea, #764ba2);\n",
       "            color: white;\n",
       "            border: none;\n",
       "            padding: 12px 25px;\n",
       "            border-radius: 25px;\n",
       "            cursor: pointer;\n",
       "            font-weight: bold;\n",
       "            margin: 10px;\n",
       "            transition: transform 0.2s;\n",
       "        }\n",
       "\n",
       "        .interactive-btn:hover {\n",
       "            transform: translateY(-2px);\n",
       "        }\n",
       "    </style>\n",
       "</head>\n",
       "<body>\n",
       "    <div class=\"container\">\n",
       "        <h1>📈 Evolution of Machine Translation</h1>\n",
       "\n",
       "        <div class=\"timeline\">\n",
       "            <div class=\"timeline-line\"></div>\n",
       "\n",
       "            <!-- Statistical MT Era -->\n",
       "            <div class=\"era\">\n",
       "                <div class=\"era-header\">\n",
       "                    <div class=\"era-title\">🔢 Statistical Machine Translation (SMT)</div>\n",
       "                    <div class=\"era-period\">1990s - 2014</div>\n",
       "                </div>\n",
       "\n",
       "                <div class=\"architecture-diagram\">\n",
       "                    <h3>Rule-Based + Statistical Approach</h3>\n",
       "                    <div class=\"phrase-table\">\n",
       "                        <div class=\"phrase-pair\">\n",
       "                            <strong>German:</strong><br>\"guten Morgen\"\n",
       "                        </div>\n",
       "                        <div class=\"phrase-pair\">\n",
       "                            <strong>→</strong><br>Translation Rules\n",
       "                        </div>\n",
       "                        <div class=\"phrase-pair\">\n",
       "                            <strong>English:</strong><br>\"good morning\"\n",
       "                        </div>\n",
       "                        <div class=\"phrase-pair\">\n",
       "                            <strong>German:</strong><br>\"ich bin\"\n",
       "                        </div>\n",
       "                        <div class=\"phrase-pair\">\n",
       "                            <strong>→</strong><br>Phrase Table\n",
       "                        </div>\n",
       "                        <div class=\"phrase-pair\">\n",
       "                            <strong>English:</strong><br>\"I am\"\n",
       "                        </div>\n",
       "                        <div class=\"phrase-pair\">\n",
       "                            <strong>German:</strong><br>\"das Haus\"\n",
       "                        </div>\n",
       "                        <div class=\"phrase-pair\">\n",
       "                            <strong>→</strong><br>Word Alignment\n",
       "                        </div>\n",
       "                        <div class=\"phrase-pair\">\n",
       "                            <strong>English:</strong><br>\"the house\"\n",
       "                        </div>\n",
       "                    </div>\n",
       "                </div>\n",
       "\n",
       "                <div class=\"example\">\n",
       "                    <strong>How it worked:</strong> Break sentences into phrases, look up each phrase in a massive translation table, then use language models to make the output sound natural.\n",
       "                </div>\n",
       "\n",
       "                <div class=\"quality-meter\">\n",
       "                    <strong>Translation Quality:</strong>\n",
       "                    <div class=\"quality-bar\">\n",
       "                        <div class=\"quality-fill\" style=\"width: 40%; background: linear-gradient(90deg, #ff8787, #fa5252);\"></div>\n",
       "                    </div>\n",
       "                    <span>40% - Basic but limited</span>\n",
       "                </div>\n",
       "\n",
       "                <div class=\"pros-cons\">\n",
       "                    <div class=\"pros\">\n",
       "                        <h4>✅ Pros:</h4>\n",
       "                        • Fast and predictable<br>\n",
       "                        • Works with limited data<br>\n",
       "                        • Interpretable rules\n",
       "                    </div>\n",
       "                    <div class=\"cons\">\n",
       "                        <h4>❌ Cons:</h4>\n",
       "                        • Rigid word-by-word translation<br>\n",
       "                        • Can't handle context well<br>\n",
       "                        • Awkward, unnatural output\n",
       "                    </div>\n",
       "                </div>\n",
       "            </div>\n",
       "\n",
       "            <!-- Early RNN Era -->\n",
       "            <div class=\"era\">\n",
       "                <div class=\"era-header\">\n",
       "                    <div class=\"era-title\">🧠 Early RNN Translation</div>\n",
       "                    <div class=\"era-period\">2013 - 2014</div>\n",
       "                </div>\n",
       "\n",
       "                <div class=\"architecture-diagram\">\n",
       "                    <h3>Direct RNN Mapping (Failed Approach)</h3>\n",
       "                    <div class=\"flow-diagram\">\n",
       "                        <div style=\"background: #e3f2fd; padding: 10px; border-radius: 8px; margin: 5px;\">Ich</div>\n",
       "                        <div class=\"arrow\">→</div>\n",
       "                        <div class=\"nn-component\">RNN</div>\n",
       "                        <div class=\"arrow\">→</div>\n",
       "                        <div style=\"background: #e8f5e8; padding: 10px; border-radius: 8px; margin: 5px;\">I</div>\n",
       "                    </div>\n",
       "                    <div class=\"flow-diagram\">\n",
       "                        <div style=\"background: #e3f2fd; padding: 10px; border-radius: 8px; margin: 5px;\">liebe</div>\n",
       "                        <div class=\"arrow\">→</div>\n",
       "                        <div class=\"nn-component\">RNN</div>\n",
       "                        <div class=\"arrow\">→</div>\n",
       "                        <div style=\"background: #e8f5e8; padding: 10px; border-radius: 8px; margin: 5px;\">love</div>\n",
       "                    </div>\n",
       "                    <div class=\"flow-diagram\">\n",
       "                        <div style=\"background: #e3f2fd; padding: 10px; border-radius: 8px; margin: 5px;\">dich</div>\n",
       "                        <div class=\"arrow\">→</div>\n",
       "                        <div class=\"nn-component\">RNN</div>\n",
       "                        <div class=\"arrow\">→</div>\n",
       "                        <div style=\"background: #e8f5e8; padding: 10px; border-radius: 8px; margin: 5px;\">you</div>\n",
       "                    </div>\n",
       "                </div>\n",
       "\n",
       "                <div class=\"example\">\n",
       "                    <strong>Problem:</strong> \"Ich habe das Buch gelesen\" → Direct mapping fails because \"gelesen\" (read) should come earlier in English: \"I have <strong>read</strong> the book\"\n",
       "                </div>\n",
       "\n",
       "                <div class=\"quality-meter\">\n",
       "                    <strong>Translation Quality:</strong>\n",
       "                    <div class=\"quality-bar\">\n",
       "                        <div class=\"quality-fill\" style=\"width: 25%; background: linear-gradient(90deg, #e53e3e, #c53030);\"></div>\n",
       "                    </div>\n",
       "                    <span>25% - Worse than SMT</span>\n",
       "                </div>\n",
       "\n",
       "                <div class=\"pros-cons\">\n",
       "                    <div class=\"pros\">\n",
       "                        <h4>✅ Pros:</h4>\n",
       "                        • Neural networks can learn<br>\n",
       "                        • End-to-end training<br>\n",
       "                        • Potential for improvement\n",
       "                    </div>\n",
       "                    <div class=\"cons\">\n",
       "                        <h4>❌ Cons:</h4>\n",
       "                        • Word order problems<br>\n",
       "                        • Length mismatches<br>\n",
       "                        • Couldn't capture sentence meaning\n",
       "                    </div>\n",
       "                </div>\n",
       "            </div>\n",
       "\n",
       "            <!-- Seq2Seq RNN Era -->\n",
       "            <div class=\"era\">\n",
       "                <div class=\"era-header\">\n",
       "                    <div class=\"era-title\">🔄 Seq2Seq RNN/LSTM</div>\n",
       "                    <div class=\"era-period\">2014 - 2016</div>\n",
       "                </div>\n",
       "\n",
       "                <div class=\"architecture-diagram\">\n",
       "                    <h3>Encoder-Decoder Architecture</h3>\n",
       "                    <div class=\"flow-diagram\">\n",
       "                        <div style=\"background: #e3f2fd; padding: 10px; border-radius: 8px; margin: 5px;\">Ich<br>liebe<br>dich</div>\n",
       "                        <div class=\"arrow\">→</div>\n",
       "                        <div class=\"nn-component encoder\">ENCODER<br>RNN/LSTM</div>\n",
       "                        <div class=\"arrow\">→</div>\n",
       "                        <div style=\"background: #fff3e0; padding: 15px; border-radius: 8px; margin: 5px; border: 2px solid #ff9800;\">\n",
       "                            <strong>Context Vector</strong><br>\n",
       "                            <span style=\"font-size: 12px;\">[0.3, -0.1, 0.8, ...]</span>\n",
       "                        </div>\n",
       "                        <div class=\"arrow\">→</div>\n",
       "                        <div class=\"nn-component decoder\">DECODER<br>RNN/LSTM</div>\n",
       "                        <div class=\"arrow\">→</div>\n",
       "                        <div style=\"background: #e8f5e8; padding: 10px; border-radius: 8px; margin: 5px;\">I<br>love<br>you</div>\n",
       "                    </div>\n",
       "                </div>\n",
       "\n",
       "                <div class=\"example\">\n",
       "                    <strong>Breakthrough:</strong> Encoder reads entire German sentence first, creates a \"meaning vector\", then decoder generates English from that understanding. Order problems solved!\n",
       "                </div>\n",
       "\n",
       "                <div class=\"quality-meter\">\n",
       "                    <strong>Translation Quality:</strong>\n",
       "                    <div class=\"quality-bar\">\n",
       "                        <div class=\"quality-fill\" style=\"width: 65%; background: linear-gradient(90deg, #ffd43b, #fab005);\"></div>\n",
       "                    </div>\n",
       "                    <span>65% - Major improvement!</span>\n",
       "                </div>\n",
       "\n",
       "                <div class=\"pros-cons\">\n",
       "                    <div class=\"pros\">\n",
       "                        <h4>✅ Pros:</h4>\n",
       "                        • Understands full sentence meaning<br>\n",
       "                        • Handles word order differences<br>\n",
       "                        • Variable length input/output<br>\n",
       "                        • Much better fluency\n",
       "                    </div>\n",
       "                    <div class=\"cons\">\n",
       "                        <h4>❌ Cons:</h4>\n",
       "                        • Context vector bottleneck<br>\n",
       "                        • Forgets long sentences<br>\n",
       "                        • Still struggles with very long text\n",
       "                    </div>\n",
       "                </div>\n",
       "            </div>\n",
       "\n",
       "            <!-- Attention Era -->\n",
       "            <div class=\"era\">\n",
       "                <div class=\"era-header\">\n",
       "                    <div class=\"era-title\">👁️ RNN/LSTM + Attention</div>\n",
       "                    <div class=\"era-period\">2015 - 2017</div>\n",
       "                </div>\n",
       "\n",
       "                <div class=\"architecture-diagram\">\n",
       "                    <h3>Encoder-Decoder + Attention Mechanism</h3>\n",
       "                    <div class=\"flow-diagram\" style=\"flex-direction: column;\">\n",
       "                        <div style=\"display: flex; align-items: center; margin: 10px 0;\">\n",
       "                            <div style=\"background: #e3f2fd; padding: 10px; border-radius: 8px; margin: 5px;\">Ich liebe dich</div>\n",
       "                            <div class=\"arrow\">→</div>\n",
       "                            <div class=\"nn-component encoder\">ENCODER<br>RNN/LSTM</div>\n",
       "                            <div class=\"arrow\">→</div>\n",
       "                            <div style=\"background: #fff3e0; padding: 10px; border-radius: 8px; margin: 5px;\">h₁ h₂ h₃<br><span style=\"font-size: 12px;\">All hidden states</span></div>\n",
       "                        </div>\n",
       "\n",
       "                        <div class=\"nn-component attention\" style=\"margin: 20px auto;\">\n",
       "                            ATTENTION MECHANISM<br>\n",
       "                            <span style=\"font-size: 12px;\">Looks at relevant parts</span>\n",
       "                        </div>\n",
       "\n",
       "                        <div class=\"attention-matrix\">\n",
       "                            <div class=\"attention-cell\" style=\"background: #4caf50;\">0.8</div>\n",
       "                            <div class=\"attention-cell\" style=\"background: #8bc34a;\">0.1</div>\n",
       "                            <div class=\"attention-cell\" style=\"background: #cddc39;\">0.1</div>\n",
       "                            <div style=\"font-size: 12px; text-align: center; color: #666;\">Generating \"I\"</div>\n",
       "\n",
       "                            <div class=\"attention-cell\" style=\"background: #cddc39;\">0.1</div>\n",
       "                            <div class=\"attention-cell\" style=\"background: #4caf50;\">0.8</div>\n",
       "                            <div class=\"attention-cell\" style=\"background: #8bc34a;\">0.1</div>\n",
       "                            <div style=\"font-size: 12px; text-align: center; color: #666;\">Generating \"love\"</div>\n",
       "\n",
       "                            <div class=\"attention-cell\" style=\"background: #8bc34a;\">0.1</div>\n",
       "                            <div class=\"attention-cell\" style=\"background: #cddc39;\">0.1</div>\n",
       "                            <div class=\"attention-cell\" style=\"background: #4caf50;\">0.8</div>\n",
       "                            <div style=\"font-size: 12px; text-align: center; color: #666;\">Generating \"you\"</div>\n",
       "                        </div>\n",
       "\n",
       "                        <div style=\"display: flex; align-items: center; margin: 10px 0;\">\n",
       "                            <div class=\"nn-component decoder\">DECODER<br>RNN/LSTM</div>\n",
       "                            <div class=\"arrow\">→</div>\n",
       "                            <div style=\"background: #e8f5e8; padding: 10px; border-radius: 8px; margin: 5px;\">I love you</div>\n",
       "                        </div>\n",
       "                    </div>\n",
       "                </div>\n",
       "\n",
       "                <div class=\"example\">\n",
       "                    <strong>Innovation:</strong> Decoder can \"look back\" at specific parts of the input sentence when generating each output word. No more information bottleneck!\n",
       "                </div>\n",
       "\n",
       "                <div class=\"quality-meter\">\n",
       "                    <strong>Translation Quality:</strong>\n",
       "                    <div class=\"quality-bar\">\n",
       "                        <div class=\"quality-fill\" style=\"width: 80%; background: linear-gradient(90deg, #51cf66, #40c057);\"></div>\n",
       "                    </div>\n",
       "                    <span>80% - Near human-level for short sentences</span>\n",
       "                </div>\n",
       "\n",
       "                <div class=\"pros-cons\">\n",
       "                    <div class=\"pros\">\n",
       "                        <h4>✅ Pros:</h4>\n",
       "                        • Solves long sentence problem<br>\n",
       "                        • Can align input/output words<br>\n",
       "                        • Much better context understanding<br>\n",
       "                        • Interpretable attention weights\n",
       "                    </div>\n",
       "                    <div class=\"cons\">\n",
       "                        <h4>❌ Cons:</h4>\n",
       "                        • Still sequential processing<br>\n",
       "                        • Slow training and inference<br>\n",
       "                        • RNN limitations remain\n",
       "                    </div>\n",
       "                </div>\n",
       "            </div>\n",
       "\n",
       "            <!-- Transformer Era -->\n",
       "            <div class=\"era\">\n",
       "                <div class=\"era-header\">\n",
       "                    <div class=\"era-title\">⚡ Transformers</div>\n",
       "                    <div class=\"era-period\">2017 - Present</div>\n",
       "                </div>\n",
       "\n",
       "                <div class=\"architecture-diagram\">\n",
       "                    <h3>\"Attention is All You Need\"</h3>\n",
       "                    <div class=\"flow-diagram\" style=\"flex-direction: column;\">\n",
       "                        <div style=\"display: flex; align-items: center; margin: 10px 0;\">\n",
       "                            <div style=\"background: #e3f2fd; padding: 10px; border-radius: 8px; margin: 5px;\">Ich liebe dich</div>\n",
       "                            <div class=\"arrow\">→</div>\n",
       "                            <div class=\"nn-component transformer\">TRANSFORMER<br>ENCODER</div>\n",
       "                            <div class=\"arrow\">→</div>\n",
       "                            <div style=\"background: #fff3e0; padding: 10px; border-radius: 8px; margin: 5px;\">Contextual<br>Representations</div>\n",
       "                        </div>\n",
       "\n",
       "                        <div class=\"nn-component attention\" style=\"margin: 20px auto; width: 300px;\">\n",
       "                            MULTI-HEAD SELF-ATTENTION<br>\n",
       "                            <span style=\"font-size: 12px;\">Parallel processing + full context</span>\n",
       "                        </div>\n",
       "\n",
       "                        <div style=\"display: flex; align-items: center; margin: 10px 0;\">\n",
       "                            <div class=\"nn-component transformer\">TRANSFORMER<br>DECODER</div>\n",
       "                            <div class=\"arrow\">→</div>\n",
       "                            <div style=\"background: #e8f5e8; padding: 10px; border-radius: 8px; margin: 5px;\">I love you</div>\n",
       "                        </div>\n",
       "                    </div>\n",
       "                </div>\n",
       "\n",
       "                <div class=\"example\">\n",
       "                    <strong>Revolution:</strong> No RNNs at all! Pure attention mechanisms process all words in parallel. Each word can attend to every other word simultaneously.\n",
       "                </div>\n",
       "\n",
       "                <div class=\"quality-meter\">\n",
       "                    <strong>Translation Quality:</strong>\n",
       "                    <div class=\"quality-bar\">\n",
       "                        <div class=\"quality-fill\" style=\"width: 95%; background: linear-gradient(90deg, #667eea, #764ba2);\"></div>\n",
       "                    </div>\n",
       "                    <span>95% - Human-level for most content</span>\n",
       "                </div>\n",
       "\n",
       "                <div class=\"pros-cons\">\n",
       "                    <div class=\"pros\">\n",
       "                        <h4>✅ Pros:</h4>\n",
       "                        • Parallel processing (much faster)<br>\n",
       "                        • Perfect long-range dependencies<br>\n",
       "                        • Scales to massive datasets<br>\n",
       "                        • State-of-the-art results<br>\n",
       "                        • Transfer learning capability\n",
       "                    </div>\n",
       "                    <div class=\"cons\">\n",
       "                        <h4>❌ Cons:</h4>\n",
       "                        • Computationally expensive<br>\n",
       "                        • Requires lots of data<br>\n",
       "                        • Complex architecture<br>\n",
       "                        • Memory intensive\n",
       "                    </div>\n",
       "                </div>\n",
       "            </div>\n",
       "        </div>\n",
       "\n",
       "        <div style=\"text-align: center; margin: 40px 0;\">\n",
       "            <button class=\"interactive-btn\" onclick=\"animateEvolution()\">🚀 Animate Evolution</button>\n",
       "            <button class=\"interactive-btn\" onclick=\"showComparison()\">📊 Compare All Methods</button>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <script>\n",
       "        function animateEvolution() {\n",
       "            const eras = document.querySelectorAll('.era');\n",
       "            eras.forEach((era, index) => {\n",
       "                era.style.opacity = '0.3';\n",
       "                era.style.transform = 'translateX(-50px)';\n",
       "\n",
       "                setTimeout(() => {\n",
       "                    era.style.transition = 'all 0.8s ease';\n",
       "                    era.style.opacity = '1';\n",
       "                    era.style.transform = 'translateX(0)';\n",
       "                }, index * 1000);\n",
       "            });\n",
       "        }\n",
       "\n",
       "        function showComparison() {\n",
       "            const qualities = [40, 25, 65, 80, 95];\n",
       "            const labels = ['SMT', 'Early RNN', 'Seq2Seq', 'RNN+Attention', 'Transformers'];\n",
       "            const colors = [\n",
       "                'linear-gradient(90deg, #ff8787, #fa5252)',\n",
       "                'linear-gradient(90deg, #e53e3e, #c53030)',\n",
       "                'linear-gradient(90deg, #ffd43b, #fab005)',\n",
       "                'linear-gradient(90deg, #51cf66, #40c057)',\n",
       "                'linear-gradient(90deg, #667eea, #764ba2)'\n",
       "            ];\n",
       "\n",
       "            // Create comparison popup\n",
       "            const popup = document.createElement('div');\n",
       "            popup.style.cssText = `\n",
       "                position: fixed;\n",
       "                top: 50%;\n",
       "                left: 50%;\n",
       "                transform: translate(-50%, -50%);\n",
       "                background: white;\n",
       "                padding: 40px;\n",
       "                border-radius: 20px;\n",
       "                box-shadow: 0 20px 60px rgba(0,0,0,0.3);\n",
       "                z-index: 1000;\n",
       "                max-width: 600px;\n",
       "                width: 90%;\n",
       "            `;\n",
       "\n",
       "            popup.innerHTML = `\n",
       "                <h2>Translation Quality Comparison</h2>\n",
       "                ${qualities.map((quality, index) => `\n",
       "                    <div style=\"margin: 15px 0; display: flex; align-items: center;\">\n",
       "                        <span style=\"width: 120px; font-weight: bold;\">${labels[index]}:</span>\n",
       "                        <div style=\"width: 200px; height: 25px; background: #e2e8f0; border-radius: 12px; overflow: hidden; margin: 0 15px;\">\n",
       "                            <div style=\"width: ${quality}%; height: 100%; background: ${colors[index]}; border-radius: 12px; transition: width 1s ease;\"></div>\n",
       "                        </div>\n",
       "                        <span style=\"font-weight: bold;\">${quality}%</span>\n",
       "                    </div>\n",
       "                `).join('')}\n",
       "                <button onclick=\"this.parentElement.remove()\" style=\"background: #667eea; color: white; border: none; padding: 10px 20px; border-radius: 10px; margin-top: 20px; cursor: pointer;\">Close</button>\n",
       "            `;\n",
       "\n",
       "            document.body.appendChild(popup);\n",
       "\n",
       "            // Animate bars\n",
       "            setTimeout(() => {\n",
       "                const bars = popup.querySelectorAll('div[style*=\"width:\"]');\n",
       "                bars.forEach((bar, index) => {\n",
       "                    setTimeout(() => {\n",
       "                        bar.style.width = qualities[index] + '%';\n",
       "                    }, index * 200);\n",
       "                });\n",
       "            }, 100);\n",
       "        }\n",
       "\n",
       "        // Add initial animation\n",
       "        setTimeout(() => {\n",
       "            animateEvolution();\n",
       "        }, 1000);\n",
       "    </script>\n",
       "</body>\n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "# Copy the entire HTML content and assign it to a variable\n",
    "html_content = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Evolution of Machine Translation</title>\n",
    "    <style>\n",
    "        body {\n",
    "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "            margin: 0;\n",
    "            padding: 20px;\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            color: #333;\n",
    "        }\n",
    "\n",
    "        .container {\n",
    "            max-width: 1400px;\n",
    "            margin: 0 auto;\n",
    "        }\n",
    "\n",
    "        h1 {\n",
    "            text-align: center;\n",
    "            color: white;\n",
    "            font-size: 2.5em;\n",
    "            margin-bottom: 40px;\n",
    "            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);\n",
    "        }\n",
    "\n",
    "        .timeline {\n",
    "            display: flex;\n",
    "            flex-direction: column;\n",
    "            gap: 40px;\n",
    "        }\n",
    "\n",
    "        .era {\n",
    "            background: white;\n",
    "            border-radius: 20px;\n",
    "            padding: 30px;\n",
    "            box-shadow: 0 10px 30px rgba(0,0,0,0.1);\n",
    "            position: relative;\n",
    "            margin-left: 50px;\n",
    "        }\n",
    "\n",
    "        .era::before {\n",
    "            content: '';\n",
    "            position: absolute;\n",
    "            left: -50px;\n",
    "            top: 30px;\n",
    "            width: 40px;\n",
    "            height: 40px;\n",
    "            border-radius: 50%;\n",
    "            background: linear-gradient(45deg, #667eea, #764ba2);\n",
    "            color: white;\n",
    "            display: flex;\n",
    "            align-items: center;\n",
    "            justify-content: center;\n",
    "            font-weight: bold;\n",
    "            z-index: 2;\n",
    "        }\n",
    "\n",
    "        .timeline-line {\n",
    "            position: absolute;\n",
    "            left: -30px;\n",
    "            top: 0;\n",
    "            bottom: 0;\n",
    "            width: 4px;\n",
    "            background: linear-gradient(to bottom, #667eea, #764ba2);\n",
    "            z-index: 1;\n",
    "        }\n",
    "\n",
    "        .era-header {\n",
    "            display: flex;\n",
    "            justify-content: space-between;\n",
    "            align-items: center;\n",
    "            margin-bottom: 20px;\n",
    "            padding-bottom: 15px;\n",
    "            border-bottom: 3px solid #e2e8f0;\n",
    "        }\n",
    "\n",
    "        .era-title {\n",
    "            font-size: 1.8em;\n",
    "            font-weight: bold;\n",
    "            color: #2d3748;\n",
    "        }\n",
    "\n",
    "        .era-period {\n",
    "            background: linear-gradient(45deg, #667eea, #764ba2);\n",
    "            color: white;\n",
    "            padding: 8px 16px;\n",
    "            border-radius: 20px;\n",
    "            font-weight: bold;\n",
    "        }\n",
    "\n",
    "        .architecture-diagram {\n",
    "            background: #f8f9fa;\n",
    "            border: 2px solid #e2e8f0;\n",
    "            border-radius: 15px;\n",
    "            padding: 25px;\n",
    "            margin: 20px 0;\n",
    "            text-align: center;\n",
    "        }\n",
    "\n",
    "        .example {\n",
    "            background: #e3f2fd;\n",
    "            border-left: 4px solid #2196f3;\n",
    "            padding: 15px;\n",
    "            margin: 15px 0;\n",
    "            border-radius: 0 10px 10px 0;\n",
    "        }\n",
    "\n",
    "        .pros-cons {\n",
    "            display: grid;\n",
    "            grid-template-columns: 1fr 1fr;\n",
    "            gap: 20px;\n",
    "            margin: 20px 0;\n",
    "        }\n",
    "\n",
    "        .pros {\n",
    "            background: #e8f5e8;\n",
    "            border: 2px solid #4caf50;\n",
    "            border-radius: 10px;\n",
    "            padding: 15px;\n",
    "        }\n",
    "\n",
    "        .cons {\n",
    "            background: #ffebee;\n",
    "            border: 2px solid #f44336;\n",
    "            border-radius: 10px;\n",
    "            padding: 15px;\n",
    "        }\n",
    "\n",
    "        /* SMT Specific */\n",
    "        .phrase-table {\n",
    "            display: grid;\n",
    "            grid-template-columns: repeat(3, 1fr);\n",
    "            gap: 10px;\n",
    "            margin: 20px 0;\n",
    "        }\n",
    "\n",
    "        .phrase-pair {\n",
    "            background: #fff3e0;\n",
    "            border: 2px solid #ff9800;\n",
    "            border-radius: 8px;\n",
    "            padding: 10px;\n",
    "            text-align: center;\n",
    "            font-size: 14px;\n",
    "        }\n",
    "\n",
    "        /* Neural Network Components */\n",
    "        .nn-component {\n",
    "            display: inline-block;\n",
    "            background: linear-gradient(45deg, #ff6b6b, #ee5a52);\n",
    "            color: white;\n",
    "            padding: 15px 20px;\n",
    "            border-radius: 12px;\n",
    "            margin: 5px;\n",
    "            font-weight: bold;\n",
    "            min-width: 80px;\n",
    "            text-align: center;\n",
    "        }\n",
    "\n",
    "        .nn-component.encoder {\n",
    "            background: linear-gradient(45deg, #4ecdc4, #44a08d);\n",
    "        }\n",
    "\n",
    "        .nn-component.decoder {\n",
    "            background: linear-gradient(45deg, #a8e6cf, #7fcdcd);\n",
    "        }\n",
    "\n",
    "        .nn-component.attention {\n",
    "            background: linear-gradient(45deg, #ffd93d, #ff9f1a);\n",
    "        }\n",
    "\n",
    "        .nn-component.transformer {\n",
    "            background: linear-gradient(45deg, #667eea, #764ba2);\n",
    "        }\n",
    "\n",
    "        .arrow {\n",
    "            display: inline-block;\n",
    "            margin: 0 10px;\n",
    "            font-size: 20px;\n",
    "            color: #4a5568;\n",
    "        }\n",
    "\n",
    "        .flow-diagram {\n",
    "            display: flex;\n",
    "            align-items: center;\n",
    "            justify-content: center;\n",
    "            flex-wrap: wrap;\n",
    "            margin: 20px 0;\n",
    "        }\n",
    "\n",
    "        .attention-matrix {\n",
    "            display: grid;\n",
    "            grid-template-columns: repeat(4, 40px);\n",
    "            gap: 2px;\n",
    "            margin: 20px auto;\n",
    "            width: fit-content;\n",
    "        }\n",
    "\n",
    "        .attention-cell {\n",
    "            width: 40px;\n",
    "            height: 40px;\n",
    "            border-radius: 4px;\n",
    "            display: flex;\n",
    "            align-items: center;\n",
    "            justify-content: center;\n",
    "            font-size: 12px;\n",
    "            color: white;\n",
    "            font-weight: bold;\n",
    "        }\n",
    "\n",
    "        .quality-meter {\n",
    "            display: flex;\n",
    "            align-items: center;\n",
    "            margin: 15px 0;\n",
    "        }\n",
    "\n",
    "        .quality-bar {\n",
    "            width: 200px;\n",
    "            height: 20px;\n",
    "            background: #e2e8f0;\n",
    "            border-radius: 10px;\n",
    "            margin: 0 15px;\n",
    "            overflow: hidden;\n",
    "        }\n",
    "\n",
    "        .quality-fill {\n",
    "            height: 100%;\n",
    "            border-radius: 10px;\n",
    "            transition: width 0.5s ease;\n",
    "        }\n",
    "\n",
    "        .interactive-btn {\n",
    "            background: linear-gradient(45deg, #667eea, #764ba2);\n",
    "            color: white;\n",
    "            border: none;\n",
    "            padding: 12px 25px;\n",
    "            border-radius: 25px;\n",
    "            cursor: pointer;\n",
    "            font-weight: bold;\n",
    "            margin: 10px;\n",
    "            transition: transform 0.2s;\n",
    "        }\n",
    "\n",
    "        .interactive-btn:hover {\n",
    "            transform: translateY(-2px);\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"container\">\n",
    "        <h1>📈 Evolution of Machine Translation</h1>\n",
    "\n",
    "        <div class=\"timeline\">\n",
    "            <div class=\"timeline-line\"></div>\n",
    "\n",
    "            <!-- Statistical MT Era -->\n",
    "            <div class=\"era\">\n",
    "                <div class=\"era-header\">\n",
    "                    <div class=\"era-title\">🔢 Statistical Machine Translation (SMT)</div>\n",
    "                    <div class=\"era-period\">1990s - 2014</div>\n",
    "                </div>\n",
    "\n",
    "                <div class=\"architecture-diagram\">\n",
    "                    <h3>Rule-Based + Statistical Approach</h3>\n",
    "                    <div class=\"phrase-table\">\n",
    "                        <div class=\"phrase-pair\">\n",
    "                            <strong>German:</strong><br>\"guten Morgen\"\n",
    "                        </div>\n",
    "                        <div class=\"phrase-pair\">\n",
    "                            <strong>→</strong><br>Translation Rules\n",
    "                        </div>\n",
    "                        <div class=\"phrase-pair\">\n",
    "                            <strong>English:</strong><br>\"good morning\"\n",
    "                        </div>\n",
    "                        <div class=\"phrase-pair\">\n",
    "                            <strong>German:</strong><br>\"ich bin\"\n",
    "                        </div>\n",
    "                        <div class=\"phrase-pair\">\n",
    "                            <strong>→</strong><br>Phrase Table\n",
    "                        </div>\n",
    "                        <div class=\"phrase-pair\">\n",
    "                            <strong>English:</strong><br>\"I am\"\n",
    "                        </div>\n",
    "                        <div class=\"phrase-pair\">\n",
    "                            <strong>German:</strong><br>\"das Haus\"\n",
    "                        </div>\n",
    "                        <div class=\"phrase-pair\">\n",
    "                            <strong>→</strong><br>Word Alignment\n",
    "                        </div>\n",
    "                        <div class=\"phrase-pair\">\n",
    "                            <strong>English:</strong><br>\"the house\"\n",
    "                        </div>\n",
    "                    </div>\n",
    "                </div>\n",
    "\n",
    "                <div class=\"example\">\n",
    "                    <strong>How it worked:</strong> Break sentences into phrases, look up each phrase in a massive translation table, then use language models to make the output sound natural.\n",
    "                </div>\n",
    "\n",
    "                <div class=\"quality-meter\">\n",
    "                    <strong>Translation Quality:</strong>\n",
    "                    <div class=\"quality-bar\">\n",
    "                        <div class=\"quality-fill\" style=\"width: 40%; background: linear-gradient(90deg, #ff8787, #fa5252);\"></div>\n",
    "                    </div>\n",
    "                    <span>40% - Basic but limited</span>\n",
    "                </div>\n",
    "\n",
    "                <div class=\"pros-cons\">\n",
    "                    <div class=\"pros\">\n",
    "                        <h4>✅ Pros:</h4>\n",
    "                        • Fast and predictable<br>\n",
    "                        • Works with limited data<br>\n",
    "                        • Interpretable rules\n",
    "                    </div>\n",
    "                    <div class=\"cons\">\n",
    "                        <h4>❌ Cons:</h4>\n",
    "                        • Rigid word-by-word translation<br>\n",
    "                        • Can't handle context well<br>\n",
    "                        • Awkward, unnatural output\n",
    "                    </div>\n",
    "                </div>\n",
    "            </div>\n",
    "\n",
    "            <!-- Early RNN Era -->\n",
    "            <div class=\"era\">\n",
    "                <div class=\"era-header\">\n",
    "                    <div class=\"era-title\">🧠 Early RNN Translation</div>\n",
    "                    <div class=\"era-period\">2013 - 2014</div>\n",
    "                </div>\n",
    "\n",
    "                <div class=\"architecture-diagram\">\n",
    "                    <h3>Direct RNN Mapping (Failed Approach)</h3>\n",
    "                    <div class=\"flow-diagram\">\n",
    "                        <div style=\"background: #e3f2fd; padding: 10px; border-radius: 8px; margin: 5px;\">Ich</div>\n",
    "                        <div class=\"arrow\">→</div>\n",
    "                        <div class=\"nn-component\">RNN</div>\n",
    "                        <div class=\"arrow\">→</div>\n",
    "                        <div style=\"background: #e8f5e8; padding: 10px; border-radius: 8px; margin: 5px;\">I</div>\n",
    "                    </div>\n",
    "                    <div class=\"flow-diagram\">\n",
    "                        <div style=\"background: #e3f2fd; padding: 10px; border-radius: 8px; margin: 5px;\">liebe</div>\n",
    "                        <div class=\"arrow\">→</div>\n",
    "                        <div class=\"nn-component\">RNN</div>\n",
    "                        <div class=\"arrow\">→</div>\n",
    "                        <div style=\"background: #e8f5e8; padding: 10px; border-radius: 8px; margin: 5px;\">love</div>\n",
    "                    </div>\n",
    "                    <div class=\"flow-diagram\">\n",
    "                        <div style=\"background: #e3f2fd; padding: 10px; border-radius: 8px; margin: 5px;\">dich</div>\n",
    "                        <div class=\"arrow\">→</div>\n",
    "                        <div class=\"nn-component\">RNN</div>\n",
    "                        <div class=\"arrow\">→</div>\n",
    "                        <div style=\"background: #e8f5e8; padding: 10px; border-radius: 8px; margin: 5px;\">you</div>\n",
    "                    </div>\n",
    "                </div>\n",
    "\n",
    "                <div class=\"example\">\n",
    "                    <strong>Problem:</strong> \"Ich habe das Buch gelesen\" → Direct mapping fails because \"gelesen\" (read) should come earlier in English: \"I have <strong>read</strong> the book\"\n",
    "                </div>\n",
    "\n",
    "                <div class=\"quality-meter\">\n",
    "                    <strong>Translation Quality:</strong>\n",
    "                    <div class=\"quality-bar\">\n",
    "                        <div class=\"quality-fill\" style=\"width: 25%; background: linear-gradient(90deg, #e53e3e, #c53030);\"></div>\n",
    "                    </div>\n",
    "                    <span>25% - Worse than SMT</span>\n",
    "                </div>\n",
    "\n",
    "                <div class=\"pros-cons\">\n",
    "                    <div class=\"pros\">\n",
    "                        <h4>✅ Pros:</h4>\n",
    "                        • Neural networks can learn<br>\n",
    "                        • End-to-end training<br>\n",
    "                        • Potential for improvement\n",
    "                    </div>\n",
    "                    <div class=\"cons\">\n",
    "                        <h4>❌ Cons:</h4>\n",
    "                        • Word order problems<br>\n",
    "                        • Length mismatches<br>\n",
    "                        • Couldn't capture sentence meaning\n",
    "                    </div>\n",
    "                </div>\n",
    "            </div>\n",
    "\n",
    "            <!-- Seq2Seq RNN Era -->\n",
    "            <div class=\"era\">\n",
    "                <div class=\"era-header\">\n",
    "                    <div class=\"era-title\">🔄 Seq2Seq RNN/LSTM</div>\n",
    "                    <div class=\"era-period\">2014 - 2016</div>\n",
    "                </div>\n",
    "\n",
    "                <div class=\"architecture-diagram\">\n",
    "                    <h3>Encoder-Decoder Architecture</h3>\n",
    "                    <div class=\"flow-diagram\">\n",
    "                        <div style=\"background: #e3f2fd; padding: 10px; border-radius: 8px; margin: 5px;\">Ich<br>liebe<br>dich</div>\n",
    "                        <div class=\"arrow\">→</div>\n",
    "                        <div class=\"nn-component encoder\">ENCODER<br>RNN/LSTM</div>\n",
    "                        <div class=\"arrow\">→</div>\n",
    "                        <div style=\"background: #fff3e0; padding: 15px; border-radius: 8px; margin: 5px; border: 2px solid #ff9800;\">\n",
    "                            <strong>Context Vector</strong><br>\n",
    "                            <span style=\"font-size: 12px;\">[0.3, -0.1, 0.8, ...]</span>\n",
    "                        </div>\n",
    "                        <div class=\"arrow\">→</div>\n",
    "                        <div class=\"nn-component decoder\">DECODER<br>RNN/LSTM</div>\n",
    "                        <div class=\"arrow\">→</div>\n",
    "                        <div style=\"background: #e8f5e8; padding: 10px; border-radius: 8px; margin: 5px;\">I<br>love<br>you</div>\n",
    "                    </div>\n",
    "                </div>\n",
    "\n",
    "                <div class=\"example\">\n",
    "                    <strong>Breakthrough:</strong> Encoder reads entire German sentence first, creates a \"meaning vector\", then decoder generates English from that understanding. Order problems solved!\n",
    "                </div>\n",
    "\n",
    "                <div class=\"quality-meter\">\n",
    "                    <strong>Translation Quality:</strong>\n",
    "                    <div class=\"quality-bar\">\n",
    "                        <div class=\"quality-fill\" style=\"width: 65%; background: linear-gradient(90deg, #ffd43b, #fab005);\"></div>\n",
    "                    </div>\n",
    "                    <span>65% - Major improvement!</span>\n",
    "                </div>\n",
    "\n",
    "                <div class=\"pros-cons\">\n",
    "                    <div class=\"pros\">\n",
    "                        <h4>✅ Pros:</h4>\n",
    "                        • Understands full sentence meaning<br>\n",
    "                        • Handles word order differences<br>\n",
    "                        • Variable length input/output<br>\n",
    "                        • Much better fluency\n",
    "                    </div>\n",
    "                    <div class=\"cons\">\n",
    "                        <h4>❌ Cons:</h4>\n",
    "                        • Context vector bottleneck<br>\n",
    "                        • Forgets long sentences<br>\n",
    "                        • Still struggles with very long text\n",
    "                    </div>\n",
    "                </div>\n",
    "            </div>\n",
    "\n",
    "            <!-- Attention Era -->\n",
    "            <div class=\"era\">\n",
    "                <div class=\"era-header\">\n",
    "                    <div class=\"era-title\">👁️ RNN/LSTM + Attention</div>\n",
    "                    <div class=\"era-period\">2015 - 2017</div>\n",
    "                </div>\n",
    "\n",
    "                <div class=\"architecture-diagram\">\n",
    "                    <h3>Encoder-Decoder + Attention Mechanism</h3>\n",
    "                    <div class=\"flow-diagram\" style=\"flex-direction: column;\">\n",
    "                        <div style=\"display: flex; align-items: center; margin: 10px 0;\">\n",
    "                            <div style=\"background: #e3f2fd; padding: 10px; border-radius: 8px; margin: 5px;\">Ich liebe dich</div>\n",
    "                            <div class=\"arrow\">→</div>\n",
    "                            <div class=\"nn-component encoder\">ENCODER<br>RNN/LSTM</div>\n",
    "                            <div class=\"arrow\">→</div>\n",
    "                            <div style=\"background: #fff3e0; padding: 10px; border-radius: 8px; margin: 5px;\">h₁ h₂ h₃<br><span style=\"font-size: 12px;\">All hidden states</span></div>\n",
    "                        </div>\n",
    "\n",
    "                        <div class=\"nn-component attention\" style=\"margin: 20px auto;\">\n",
    "                            ATTENTION MECHANISM<br>\n",
    "                            <span style=\"font-size: 12px;\">Looks at relevant parts</span>\n",
    "                        </div>\n",
    "\n",
    "                        <div class=\"attention-matrix\">\n",
    "                            <div class=\"attention-cell\" style=\"background: #4caf50;\">0.8</div>\n",
    "                            <div class=\"attention-cell\" style=\"background: #8bc34a;\">0.1</div>\n",
    "                            <div class=\"attention-cell\" style=\"background: #cddc39;\">0.1</div>\n",
    "                            <div style=\"font-size: 12px; text-align: center; color: #666;\">Generating \"I\"</div>\n",
    "\n",
    "                            <div class=\"attention-cell\" style=\"background: #cddc39;\">0.1</div>\n",
    "                            <div class=\"attention-cell\" style=\"background: #4caf50;\">0.8</div>\n",
    "                            <div class=\"attention-cell\" style=\"background: #8bc34a;\">0.1</div>\n",
    "                            <div style=\"font-size: 12px; text-align: center; color: #666;\">Generating \"love\"</div>\n",
    "\n",
    "                            <div class=\"attention-cell\" style=\"background: #8bc34a;\">0.1</div>\n",
    "                            <div class=\"attention-cell\" style=\"background: #cddc39;\">0.1</div>\n",
    "                            <div class=\"attention-cell\" style=\"background: #4caf50;\">0.8</div>\n",
    "                            <div style=\"font-size: 12px; text-align: center; color: #666;\">Generating \"you\"</div>\n",
    "                        </div>\n",
    "\n",
    "                        <div style=\"display: flex; align-items: center; margin: 10px 0;\">\n",
    "                            <div class=\"nn-component decoder\">DECODER<br>RNN/LSTM</div>\n",
    "                            <div class=\"arrow\">→</div>\n",
    "                            <div style=\"background: #e8f5e8; padding: 10px; border-radius: 8px; margin: 5px;\">I love you</div>\n",
    "                        </div>\n",
    "                    </div>\n",
    "                </div>\n",
    "\n",
    "                <div class=\"example\">\n",
    "                    <strong>Innovation:</strong> Decoder can \"look back\" at specific parts of the input sentence when generating each output word. No more information bottleneck!\n",
    "                </div>\n",
    "\n",
    "                <div class=\"quality-meter\">\n",
    "                    <strong>Translation Quality:</strong>\n",
    "                    <div class=\"quality-bar\">\n",
    "                        <div class=\"quality-fill\" style=\"width: 80%; background: linear-gradient(90deg, #51cf66, #40c057);\"></div>\n",
    "                    </div>\n",
    "                    <span>80% - Near human-level for short sentences</span>\n",
    "                </div>\n",
    "\n",
    "                <div class=\"pros-cons\">\n",
    "                    <div class=\"pros\">\n",
    "                        <h4>✅ Pros:</h4>\n",
    "                        • Solves long sentence problem<br>\n",
    "                        • Can align input/output words<br>\n",
    "                        • Much better context understanding<br>\n",
    "                        • Interpretable attention weights\n",
    "                    </div>\n",
    "                    <div class=\"cons\">\n",
    "                        <h4>❌ Cons:</h4>\n",
    "                        • Still sequential processing<br>\n",
    "                        • Slow training and inference<br>\n",
    "                        • RNN limitations remain\n",
    "                    </div>\n",
    "                </div>\n",
    "            </div>\n",
    "\n",
    "            <!-- Transformer Era -->\n",
    "            <div class=\"era\">\n",
    "                <div class=\"era-header\">\n",
    "                    <div class=\"era-title\">⚡ Transformers</div>\n",
    "                    <div class=\"era-period\">2017 - Present</div>\n",
    "                </div>\n",
    "\n",
    "                <div class=\"architecture-diagram\">\n",
    "                    <h3>\"Attention is All You Need\"</h3>\n",
    "                    <div class=\"flow-diagram\" style=\"flex-direction: column;\">\n",
    "                        <div style=\"display: flex; align-items: center; margin: 10px 0;\">\n",
    "                            <div style=\"background: #e3f2fd; padding: 10px; border-radius: 8px; margin: 5px;\">Ich liebe dich</div>\n",
    "                            <div class=\"arrow\">→</div>\n",
    "                            <div class=\"nn-component transformer\">TRANSFORMER<br>ENCODER</div>\n",
    "                            <div class=\"arrow\">→</div>\n",
    "                            <div style=\"background: #fff3e0; padding: 10px; border-radius: 8px; margin: 5px;\">Contextual<br>Representations</div>\n",
    "                        </div>\n",
    "\n",
    "                        <div class=\"nn-component attention\" style=\"margin: 20px auto; width: 300px;\">\n",
    "                            MULTI-HEAD SELF-ATTENTION<br>\n",
    "                            <span style=\"font-size: 12px;\">Parallel processing + full context</span>\n",
    "                        </div>\n",
    "\n",
    "                        <div style=\"display: flex; align-items: center; margin: 10px 0;\">\n",
    "                            <div class=\"nn-component transformer\">TRANSFORMER<br>DECODER</div>\n",
    "                            <div class=\"arrow\">→</div>\n",
    "                            <div style=\"background: #e8f5e8; padding: 10px; border-radius: 8px; margin: 5px;\">I love you</div>\n",
    "                        </div>\n",
    "                    </div>\n",
    "                </div>\n",
    "\n",
    "                <div class=\"example\">\n",
    "                    <strong>Revolution:</strong> No RNNs at all! Pure attention mechanisms process all words in parallel. Each word can attend to every other word simultaneously.\n",
    "                </div>\n",
    "\n",
    "                <div class=\"quality-meter\">\n",
    "                    <strong>Translation Quality:</strong>\n",
    "                    <div class=\"quality-bar\">\n",
    "                        <div class=\"quality-fill\" style=\"width: 95%; background: linear-gradient(90deg, #667eea, #764ba2);\"></div>\n",
    "                    </div>\n",
    "                    <span>95% - Human-level for most content</span>\n",
    "                </div>\n",
    "\n",
    "                <div class=\"pros-cons\">\n",
    "                    <div class=\"pros\">\n",
    "                        <h4>✅ Pros:</h4>\n",
    "                        • Parallel processing (much faster)<br>\n",
    "                        • Perfect long-range dependencies<br>\n",
    "                        • Scales to massive datasets<br>\n",
    "                        • State-of-the-art results<br>\n",
    "                        • Transfer learning capability\n",
    "                    </div>\n",
    "                    <div class=\"cons\">\n",
    "                        <h4>❌ Cons:</h4>\n",
    "                        • Computationally expensive<br>\n",
    "                        • Requires lots of data<br>\n",
    "                        • Complex architecture<br>\n",
    "                        • Memory intensive\n",
    "                    </div>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "\n",
    "        <div style=\"text-align: center; margin: 40px 0;\">\n",
    "            <button class=\"interactive-btn\" onclick=\"animateEvolution()\">🚀 Animate Evolution</button>\n",
    "            <button class=\"interactive-btn\" onclick=\"showComparison()\">📊 Compare All Methods</button>\n",
    "        </div>\n",
    "    </div>\n",
    "\n",
    "    <script>\n",
    "        function animateEvolution() {\n",
    "            const eras = document.querySelectorAll('.era');\n",
    "            eras.forEach((era, index) => {\n",
    "                era.style.opacity = '0.3';\n",
    "                era.style.transform = 'translateX(-50px)';\n",
    "\n",
    "                setTimeout(() => {\n",
    "                    era.style.transition = 'all 0.8s ease';\n",
    "                    era.style.opacity = '1';\n",
    "                    era.style.transform = 'translateX(0)';\n",
    "                }, index * 1000);\n",
    "            });\n",
    "        }\n",
    "\n",
    "        function showComparison() {\n",
    "            const qualities = [40, 25, 65, 80, 95];\n",
    "            const labels = ['SMT', 'Early RNN', 'Seq2Seq', 'RNN+Attention', 'Transformers'];\n",
    "            const colors = [\n",
    "                'linear-gradient(90deg, #ff8787, #fa5252)',\n",
    "                'linear-gradient(90deg, #e53e3e, #c53030)',\n",
    "                'linear-gradient(90deg, #ffd43b, #fab005)',\n",
    "                'linear-gradient(90deg, #51cf66, #40c057)',\n",
    "                'linear-gradient(90deg, #667eea, #764ba2)'\n",
    "            ];\n",
    "\n",
    "            // Create comparison popup\n",
    "            const popup = document.createElement('div');\n",
    "            popup.style.cssText = `\n",
    "                position: fixed;\n",
    "                top: 50%;\n",
    "                left: 50%;\n",
    "                transform: translate(-50%, -50%);\n",
    "                background: white;\n",
    "                padding: 40px;\n",
    "                border-radius: 20px;\n",
    "                box-shadow: 0 20px 60px rgba(0,0,0,0.3);\n",
    "                z-index: 1000;\n",
    "                max-width: 600px;\n",
    "                width: 90%;\n",
    "            `;\n",
    "\n",
    "            popup.innerHTML = `\n",
    "                <h2>Translation Quality Comparison</h2>\n",
    "                ${qualities.map((quality, index) => `\n",
    "                    <div style=\"margin: 15px 0; display: flex; align-items: center;\">\n",
    "                        <span style=\"width: 120px; font-weight: bold;\">${labels[index]}:</span>\n",
    "                        <div style=\"width: 200px; height: 25px; background: #e2e8f0; border-radius: 12px; overflow: hidden; margin: 0 15px;\">\n",
    "                            <div style=\"width: ${quality}%; height: 100%; background: ${colors[index]}; border-radius: 12px; transition: width 1s ease;\"></div>\n",
    "                        </div>\n",
    "                        <span style=\"font-weight: bold;\">${quality}%</span>\n",
    "                    </div>\n",
    "                `).join('')}\n",
    "                <button onclick=\"this.parentElement.remove()\" style=\"background: #667eea; color: white; border: none; padding: 10px 20px; border-radius: 10px; margin-top: 20px; cursor: pointer;\">Close</button>\n",
    "            `;\n",
    "\n",
    "            document.body.appendChild(popup);\n",
    "\n",
    "            // Animate bars\n",
    "            setTimeout(() => {\n",
    "                const bars = popup.querySelectorAll('div[style*=\"width:\"]');\n",
    "                bars.forEach((bar, index) => {\n",
    "                    setTimeout(() => {\n",
    "                        bar.style.width = qualities[index] + '%';\n",
    "                    }, index * 200);\n",
    "                });\n",
    "            }, 100);\n",
    "        }\n",
    "\n",
    "        // Add initial animation\n",
    "        setTimeout(() => {\n",
    "            animateEvolution();\n",
    "        }, 1000);\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Display it\n",
    "HTML(html_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T12:54:56.829294Z",
     "start_time": "2025-08-21T12:54:56.788610Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "    <meta charset=\"UTF-8\">\n",
       "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
       "    <title>ML Model Diagrams</title>\n",
       "    <style>\n",
       "        body {\n",
       "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
       "            margin: 0;\n",
       "            padding: 20px;\n",
       "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
       "            color: #333;\n",
       "        }\n",
       "\n",
       "        .container {\n",
       "            max-width: 1400px;\n",
       "            margin: 0 auto;\n",
       "        }\n",
       "\n",
       "        .diagram-section {\n",
       "            background: white;\n",
       "            border-radius: 15px;\n",
       "            padding: 30px;\n",
       "            margin: 30px 0;\n",
       "            box-shadow: 0 10px 30px rgba(0,0,0,0.1);\n",
       "        }\n",
       "\n",
       "        h1 {\n",
       "            text-align: center;\n",
       "            color: white;\n",
       "            font-size: 2.5em;\n",
       "            margin-bottom: 40px;\n",
       "            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);\n",
       "        }\n",
       "\n",
       "        h2 {\n",
       "            color: #4a5568;\n",
       "            border-bottom: 3px solid #667eea;\n",
       "            padding-bottom: 10px;\n",
       "            margin-bottom: 25px;\n",
       "        }\n",
       "\n",
       "        /* RNN Architecture */\n",
       "        .rnn-architecture {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            align-items: center;\n",
       "            margin: 40px 0;\n",
       "        }\n",
       "\n",
       "        .sequence-input {\n",
       "            display: flex;\n",
       "            gap: 20px;\n",
       "            margin-bottom: 30px;\n",
       "        }\n",
       "\n",
       "        .input-word {\n",
       "            background: #e3f2fd;\n",
       "            border: 2px solid #2196f3;\n",
       "            border-radius: 10px;\n",
       "            padding: 15px 20px;\n",
       "            font-weight: bold;\n",
       "            color: #1976d2;\n",
       "        }\n",
       "\n",
       "        .rnn-layer {\n",
       "            display: flex;\n",
       "            align-items: center;\n",
       "            gap: 20px;\n",
       "            margin: 20px 0;\n",
       "        }\n",
       "\n",
       "        .rnn-cell {\n",
       "            width: 100px;\n",
       "            height: 80px;\n",
       "            background: linear-gradient(45deg, #ff6b6b, #ee5a52);\n",
       "            border-radius: 15px;\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            align-items: center;\n",
       "            justify-content: center;\n",
       "            color: white;\n",
       "            font-weight: bold;\n",
       "            position: relative;\n",
       "        }\n",
       "\n",
       "        .hidden-state {\n",
       "            position: absolute;\n",
       "            top: -40px;\n",
       "            background: #fff3e0;\n",
       "            border: 2px solid #ff9800;\n",
       "            border-radius: 8px;\n",
       "            padding: 5px 10px;\n",
       "            font-size: 12px;\n",
       "            color: #e65100;\n",
       "            font-weight: bold;\n",
       "        }\n",
       "\n",
       "        .rnn-arrow {\n",
       "            width: 40px;\n",
       "            height: 3px;\n",
       "            background: #4a5568;\n",
       "            position: relative;\n",
       "        }\n",
       "\n",
       "        .rnn-arrow::after {\n",
       "            content: '';\n",
       "            position: absolute;\n",
       "            right: -8px;\n",
       "            top: -5px;\n",
       "            width: 0;\n",
       "            height: 0;\n",
       "            border-left: 12px solid #4a5568;\n",
       "            border-top: 6px solid transparent;\n",
       "            border-bottom: 6px solid transparent;\n",
       "        }\n",
       "\n",
       "        .vertical-arrow {\n",
       "            width: 3px;\n",
       "            height: 30px;\n",
       "            background: #4a5568;\n",
       "            position: relative;\n",
       "            margin: 10px auto;\n",
       "        }\n",
       "\n",
       "        .vertical-arrow::after {\n",
       "            content: '';\n",
       "            position: absolute;\n",
       "            bottom: -8px;\n",
       "            left: -5px;\n",
       "            width: 0;\n",
       "            height: 0;\n",
       "            border-top: 12px solid #4a5568;\n",
       "            border-left: 6px solid transparent;\n",
       "            border-right: 6px solid transparent;\n",
       "        }\n",
       "\n",
       "        /* LSTM Architecture */\n",
       "        .lstm-cell {\n",
       "            width: 140px;\n",
       "            height: 120px;\n",
       "            background: linear-gradient(45deg, #4ecdc4, #44a08d);\n",
       "            border-radius: 20px;\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            align-items: center;\n",
       "            justify-content: space-around;\n",
       "            color: white;\n",
       "            font-weight: bold;\n",
       "            position: relative;\n",
       "            padding: 10px;\n",
       "        }\n",
       "\n",
       "        .lstm-gate {\n",
       "            background: rgba(255,255,255,0.3);\n",
       "            border-radius: 8px;\n",
       "            padding: 5px 8px;\n",
       "            font-size: 10px;\n",
       "            margin: 2px 0;\n",
       "            text-align: center;\n",
       "        }\n",
       "\n",
       "        .forget-gate { background: rgba(255,87,87,0.8); }\n",
       "        .input-gate { background: rgba(72,187,120,0.8); }\n",
       "        .output-gate { background: rgba(66,153,225,0.8); }\n",
       "\n",
       "        .cell-state {\n",
       "            position: absolute;\n",
       "            top: -50px;\n",
       "            left: 50%;\n",
       "            transform: translateX(-50%);\n",
       "            background: #ffd54f;\n",
       "            border: 3px solid #ff8f00;\n",
       "            border-radius: 10px;\n",
       "            padding: 8px 12px;\n",
       "            font-size: 12px;\n",
       "            color: #e65100;\n",
       "            font-weight: bold;\n",
       "        }\n",
       "\n",
       "        /* Beam Search Detailed */\n",
       "        .beam-container {\n",
       "            margin: 40px 0;\n",
       "        }\n",
       "\n",
       "        .beam-step {\n",
       "            margin: 30px 0;\n",
       "            padding: 20px;\n",
       "            border: 2px solid #e2e8f0;\n",
       "            border-radius: 15px;\n",
       "            background: #f8f9fa;\n",
       "        }\n",
       "\n",
       "        .beam-header {\n",
       "            font-weight: bold;\n",
       "            color: #2d3748;\n",
       "            margin-bottom: 15px;\n",
       "            font-size: 18px;\n",
       "        }\n",
       "\n",
       "        .candidates-row {\n",
       "            display: flex;\n",
       "            gap: 15px;\n",
       "            margin: 15px 0;\n",
       "            flex-wrap: wrap;\n",
       "        }\n",
       "\n",
       "        .candidate {\n",
       "            background: linear-gradient(45deg, #667eea, #764ba2);\n",
       "            color: white;\n",
       "            padding: 12px 15px;\n",
       "            border-radius: 12px;\n",
       "            min-width: 120px;\n",
       "            text-align: center;\n",
       "            position: relative;\n",
       "        }\n",
       "\n",
       "        .candidate.kept {\n",
       "            background: linear-gradient(45deg, #48bb78, #38a169);\n",
       "            border: 3px solid #22543d;\n",
       "        }\n",
       "\n",
       "        .candidate.pruned {\n",
       "            background: linear-gradient(45deg, #e53e3e, #c53030);\n",
       "            opacity: 0.6;\n",
       "            text-decoration: line-through;\n",
       "        }\n",
       "\n",
       "        .score {\n",
       "            font-size: 11px;\n",
       "            opacity: 0.9;\n",
       "            margin-top: 5px;\n",
       "        }\n",
       "\n",
       "        .beam-width {\n",
       "            background: #fed7d7;\n",
       "            border: 2px solid #e53e3e;\n",
       "            border-radius: 10px;\n",
       "            padding: 10px;\n",
       "            margin: 15px 0;\n",
       "            text-align: center;\n",
       "            font-weight: bold;\n",
       "            color: #c53030;\n",
       "        }\n",
       "\n",
       "        .pruning-explanation {\n",
       "            background: #bee3f8;\n",
       "            border: 2px solid #3182ce;\n",
       "            border-radius: 10px;\n",
       "            padding: 15px;\n",
       "            margin: 15px 0;\n",
       "            color: #2a69ac;\n",
       "        }\n",
       "\n",
       "        /* Interactive elements */\n",
       "        .interactive-btn {\n",
       "            background: linear-gradient(45deg, #667eea, #764ba2);\n",
       "            color: white;\n",
       "            border: none;\n",
       "            padding: 12px 25px;\n",
       "            border-radius: 25px;\n",
       "            cursor: pointer;\n",
       "            font-weight: bold;\n",
       "            margin: 10px;\n",
       "            transition: transform 0.2s;\n",
       "            font-size: 16px;\n",
       "        }\n",
       "\n",
       "        .interactive-btn:hover {\n",
       "            transform: translateY(-2px);\n",
       "        }\n",
       "\n",
       "        /* Transformer Flow (keeping as is) */\n",
       "        .transformer-flow {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            align-items: center;\n",
       "            gap: 30px;\n",
       "        }\n",
       "\n",
       "        .flow-step {\n",
       "            background: linear-gradient(45deg, #667eea, #764ba2);\n",
       "            color: white;\n",
       "            padding: 20px;\n",
       "            border-radius: 15px;\n",
       "            text-align: center;\n",
       "            min-width: 200px;\n",
       "            position: relative;\n",
       "        }\n",
       "\n",
       "        .flow-arrow {\n",
       "            width: 0;\n",
       "            height: 0;\n",
       "            border-left: 15px solid transparent;\n",
       "            border-right: 15px solid transparent;\n",
       "            border-top: 20px solid #667eea;\n",
       "            margin: -5px auto;\n",
       "        }\n",
       "\n",
       "        .probability-bar {\n",
       "            background: #e2e8f0;\n",
       "            height: 20px;\n",
       "            border-radius: 10px;\n",
       "            margin: 10px 0;\n",
       "            overflow: hidden;\n",
       "            position: relative;\n",
       "        }\n",
       "\n",
       "        .probability-fill {\n",
       "            height: 100%;\n",
       "            border-radius: 10px;\n",
       "            transition: width 0.5s ease;\n",
       "        }\n",
       "\n",
       "        .word-example {\n",
       "            background: #f7fafc;\n",
       "            border: 2px solid #e2e8f0;\n",
       "            border-radius: 10px;\n",
       "            padding: 15px;\n",
       "            margin: 20px 0;\n",
       "        }\n",
       "\n",
       "        .explanation {\n",
       "            background: #f8f9fa;\n",
       "            border-left: 4px solid #667eea;\n",
       "            padding: 15px;\n",
       "            margin: 20px 0;\n",
       "            border-radius: 0 10px 10px 0;\n",
       "        }\n",
       "    </style>\n",
       "</head>\n",
       "<body>\n",
       "    <div class=\"container\">\n",
       "        <h1>🤖 AI Model Architecture Deep Dive</h1>\n",
       "\n",
       "        <!-- RNN Architecture Section -->\n",
       "        <div class=\"diagram-section\">\n",
       "            <h2>1A. RNN (Recurrent Neural Network) Architecture</h2>\n",
       "            <div class=\"explanation\">\n",
       "                <strong>Key Challenge:</strong> Information from early words gets \"forgotten\" as the sequence progresses. The hidden state gets overwritten at each step.\n",
       "            </div>\n",
       "\n",
       "            <div class=\"rnn-architecture\">\n",
       "                <div class=\"sequence-input\">\n",
       "                    <div class=\"input-word\">x₁: \"The\"</div>\n",
       "                    <div class=\"input-word\">x₂: \"cat\"</div>\n",
       "                    <div class=\"input-word\">x₃: \"sat\"</div>\n",
       "                </div>\n",
       "\n",
       "                <div class=\"vertical-arrow\"></div>\n",
       "\n",
       "                <div class=\"rnn-layer\">\n",
       "                    <div class=\"rnn-cell\">\n",
       "                        <div class=\"hidden-state\">h₀: [0.0]</div>\n",
       "                        <div>RNN</div>\n",
       "                        <div style=\"font-size: 12px;\">Cell 1</div>\n",
       "                    </div>\n",
       "                    <div class=\"rnn-arrow\"></div>\n",
       "                    <div class=\"rnn-cell\">\n",
       "                        <div class=\"hidden-state\">h₁: [0.3]</div>\n",
       "                        <div>RNN</div>\n",
       "                        <div style=\"font-size: 12px;\">Cell 2</div>\n",
       "                    </div>\n",
       "                    <div class=\"rnn-arrow\"></div>\n",
       "                    <div class=\"rnn-cell\">\n",
       "                        <div class=\"hidden-state\">h₂: [0.1]</div>\n",
       "                        <div>RNN</div>\n",
       "                        <div style=\"font-size: 12px;\">Cell 3</div>\n",
       "                    </div>\n",
       "                </div>\n",
       "\n",
       "                <div class=\"explanation\">\n",
       "                    <strong>Problem:</strong> h₂ has very little information about \"The\" (the first word) because it gets diluted through multiple transformations. <br>\n",
       "                    <strong>Formula:</strong> h₂ = tanh(W·[x₂, h₁]) where h₁ = tanh(W·[x₁, h₀])\n",
       "                </div>\n",
       "            </div>\n",
       "        </div>\n",
       "\n",
       "        <!-- RNN Cell Internal Section -->\n",
       "        <div class=\"diagram-section\">\n",
       "            <h2>1B. Inside an RNN Cell</h2>\n",
       "            <div class=\"explanation\">\n",
       "                <strong>What happens inside:</strong> Simple mathematical operations that blend current input with previous memory.\n",
       "            </div>\n",
       "\n",
       "            <div style=\"display: flex; justify-content: center; align-items: center; margin: 40px 0;\">\n",
       "                <div style=\"background: #f8f9fa; border: 3px solid #667eea; border-radius: 20px; padding: 30px; position: relative; width: 400px;\">\n",
       "                    <!-- Input arrows -->\n",
       "                    <div style=\"position: absolute; top: -40px; left: 50px; text-align: center;\">\n",
       "                        <div style=\"background: #e3f2fd; border: 2px solid #2196f3; border-radius: 8px; padding: 8px 12px; font-weight: bold; color: #1976d2;\">x_t</div>\n",
       "                        <div class=\"vertical-arrow\" style=\"height: 20px; margin: 5px auto;\"></div>\n",
       "                    </div>\n",
       "                    <div style=\"position: absolute; top: -40px; right: 50px; text-align: center;\">\n",
       "                        <div style=\"background: #fff3e0; border: 2px solid #ff9800; border-radius: 8px; padding: 8px 12px; font-weight: bold; color: #e65100;\">h_{t-1}</div>\n",
       "                        <div class=\"vertical-arrow\" style=\"height: 20px; margin: 5px auto;\"></div>\n",
       "                    </div>\n",
       "\n",
       "                    <!-- Internal computation -->\n",
       "                    <div style=\"text-align: center; margin: 20px 0;\">\n",
       "                        <div style=\"background: #e8f5e8; border: 2px solid #4caf50; border-radius: 12px; padding: 15px; margin: 10px 0;\">\n",
       "                            <strong>Step 1: Combine Inputs</strong><br>\n",
       "                            <code style=\"background: white; padding: 5px; border-radius: 5px;\">combined = W_x * x_t + W_h * h_{t-1} + b</code>\n",
       "                        </div>\n",
       "                        <div style=\"background: #fff3e0; border: 2px solid #ff9800; border-radius: 12px; padding: 15px; margin: 10px 0;\">\n",
       "                            <strong>Step 2: Activation</strong><br>\n",
       "                            <code style=\"background: white; padding: 5px; border-radius: 5px;\">h_t = tanh(combined)</code>\n",
       "                        </div>\n",
       "                    </div>\n",
       "\n",
       "                    <!-- Output arrow -->\n",
       "                    <div style=\"position: absolute; bottom: -40px; left: 50%; transform: translateX(-50%); text-align: center;\">\n",
       "                        <div class=\"vertical-arrow\" style=\"height: 20px; margin: 5px auto; transform: rotate(180deg);\"></div>\n",
       "                        <div style=\"background: #fff3e0; border: 2px solid #ff9800; border-radius: 8px; padding: 8px 12px; font-weight: bold; color: #e65100;\">h_t</div>\n",
       "                    </div>\n",
       "                </div>\n",
       "            </div>\n",
       "\n",
       "            <div class=\"explanation\">\n",
       "                <strong>Problem:</strong> The same hidden state h_t serves as both memory and output. As sequences get longer, early information gets \"overwritten\" by newer information.\n",
       "            </div>\n",
       "        </div>\n",
       "\n",
       "        <!-- LSTM Cell Internal Section -->\n",
       "        <div class=\"diagram-section\">\n",
       "            <h2>1C. Inside an LSTM Cell</h2>\n",
       "            <div class=\"explanation\">\n",
       "                <strong>Key Innovation:</strong> Separate cell state (C_t) for long-term memory and hidden state (h_t) for output. Gates control information flow.\n",
       "            </div>\n",
       "\n",
       "            <div style=\"display: flex; justify-content: center; align-items: center; margin: 40px 0;\">\n",
       "                <div style=\"background: #f8f9fa; border: 3px solid #4ecdc4; border-radius: 20px; padding: 30px; position: relative; width: 500px; height: 400px;\">\n",
       "                    <!-- Inputs -->\n",
       "                    <div style=\"position: absolute; top: -40px; left: 100px; text-align: center;\">\n",
       "                        <div style=\"background: #e3f2fd; border: 2px solid #2196f3; border-radius: 8px; padding: 8px 12px; font-weight: bold; color: #1976d2;\">x_t</div>\n",
       "                        <div class=\"vertical-arrow\" style=\"height: 20px; margin: 5px auto;\"></div>\n",
       "                    </div>\n",
       "                    <div style=\"position: absolute; top: -40px; right: 100px; text-align: center;\">\n",
       "                        <div style=\"background: #fff3e0; border: 2px solid #ff9800; border-radius: 8px; padding: 8px 12px; font-weight: bold; color: #e65100;\">h_{t-1}</div>\n",
       "                        <div class=\"vertical-arrow\" style=\"height: 20px; margin: 5px auto;\"></div>\n",
       "                    </div>\n",
       "\n",
       "                    <!-- Cell state flow (top) -->\n",
       "                    <div style=\"position: absolute; top: 10px; left: 20px; right: 20px; display: flex; align-items: center;\">\n",
       "                        <div style=\"background: #ffd54f; border: 2px solid #ff8f00; border-radius: 8px; padding: 5px 10px; font-size: 12px; font-weight: bold;\">C_{t-1}</div>\n",
       "                        <div style=\"flex: 1; height: 3px; background: #ff8f00; margin: 0 10px; position: relative;\">\n",
       "                            <div style=\"position: absolute; right: -5px; top: -5px; width: 0; height: 0; border-left: 10px solid #ff8f00; border-top: 5px solid transparent; border-bottom: 5px solid transparent;\"></div>\n",
       "                        </div>\n",
       "                        <div style=\"background: #ffd54f; border: 2px solid #ff8f00; border-radius: 8px; padding: 5px 10px; font-size: 12px; font-weight: bold;\">C_t</div>\n",
       "                    </div>\n",
       "\n",
       "                    <!-- Gates (middle section) -->\n",
       "                    <div style=\"margin-top: 60px; display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 15px; text-align: center;\">\n",
       "                        <!-- Forget Gate -->\n",
       "                        <div style=\"background: rgba(255,87,87,0.8); border-radius: 12px; padding: 10px; color: white;\">\n",
       "                            <div style=\"font-weight: bold; font-size: 14px;\">Forget Gate</div>\n",
       "                            <div style=\"font-size: 10px; margin: 5px 0;\">f_t = σ(W_f[h_{t-1}, x_t])</div>\n",
       "                            <div style=\"font-size: 12px;\">What to forget?</div>\n",
       "                        </div>\n",
       "\n",
       "                        <!-- Input Gate -->\n",
       "                        <div style=\"background: rgba(72,187,120,0.8); border-radius: 12px; padding: 10px; color: white;\">\n",
       "                            <div style=\"font-weight: bold; font-size: 14px;\">Input Gate</div>\n",
       "                            <div style=\"font-size: 10px; margin: 5px 0;\">i_t = σ(W_i[h_{t-1}, x_t])</div>\n",
       "                            <div style=\"font-size: 12px;\">What to store?</div>\n",
       "                        </div>\n",
       "\n",
       "                        <!-- Output Gate -->\n",
       "                        <div style=\"background: rgba(66,153,225,0.8); border-radius: 12px; padding: 10px; color: white;\">\n",
       "                            <div style=\"font-weight: bold; font-size: 14px;\">Output Gate</div>\n",
       "                            <div style=\"font-size: 10px; margin: 5px 0;\">o_t = σ(W_o[h_{t-1}, x_t])</div>\n",
       "                            <div style=\"font-size: 12px;\">What to output?</div>\n",
       "                        </div>\n",
       "                    </div>\n",
       "\n",
       "                    <!-- Cell state update -->\n",
       "                    <div style=\"margin-top: 20px; text-align: center;\">\n",
       "                        <div style=\"background: #e8f5e8; border: 2px solid #4caf50; border-radius: 12px; padding: 10px; font-size: 12px;\">\n",
       "                            <strong>Cell State Update:</strong><br>\n",
       "                            <code style=\"background: white; padding: 3px; border-radius: 3px;\">C_t = f_t ⊙ C_{t-1} + i_t ⊙ tanh(W_c[h_{t-1}, x_t])</code>\n",
       "                        </div>\n",
       "                    </div>\n",
       "\n",
       "                    <!-- Hidden state output -->\n",
       "                    <div style=\"margin-top: 15px; text-align: center;\">\n",
       "                        <div style=\"background: #fff3e0; border: 2px solid #ff9800; border-radius: 12px; padding: 10px; font-size: 12px;\">\n",
       "                            <strong>Hidden State:</strong><br>\n",
       "                            <code style=\"background: white; padding: 3px; border-radius: 3px;\">h_t = o_t ⊙ tanh(C_t)</code>\n",
       "                        </div>\n",
       "                    </div>\n",
       "\n",
       "                    <!-- Output -->\n",
       "                    <div style=\"position: absolute; bottom: -40px; left: 50%; transform: translateX(-50%); text-align: center;\">\n",
       "                        <div class=\"vertical-arrow\" style=\"height: 20px; margin: 5px auto; transform: rotate(180deg);\"></div>\n",
       "                        <div style=\"background: #fff3e0; border: 2px solid #ff9800; border-radius: 8px; padding: 8px 12px; font-weight: bold; color: #e65100;\">h_t</div>\n",
       "                    </div>\n",
       "                </div>\n",
       "            </div>\n",
       "\n",
       "            <div class=\"explanation\">\n",
       "                <strong>Key Symbols:</strong> σ = sigmoid function (0-1), ⊙ = element-wise multiplication, tanh = hyperbolic tangent (-1 to 1)<br>\n",
       "                <strong>Solution:</strong> Cell state C_t flows through with minimal changes, preserving long-term information while gates control what gets added, removed, or output.\n",
       "            </div>\n",
       "        </div>\n",
       "\n",
       "        <!-- LSTM Architecture Section -->\n",
       "        <div class=\"diagram-section\">\n",
       "            <h2>1D. LSTM (Long Short-Term Memory) Architecture</h2>\n",
       "            <div class=\"explanation\">\n",
       "                <strong>Key Innovation:</strong> Separate cell state (C) flows through unchanged unless gates decide to modify it. This preserves long-term information.\n",
       "            </div>\n",
       "\n",
       "            <div class=\"rnn-architecture\">\n",
       "                <div class=\"sequence-input\">\n",
       "                    <div class=\"input-word\">x₁: \"The\"</div>\n",
       "                    <div class=\"input-word\">x₂: \"cat\"</div>\n",
       "                    <div class=\"input-word\">x₃: \"sat\"</div>\n",
       "                </div>\n",
       "\n",
       "                <div class=\"vertical-arrow\"></div>\n",
       "\n",
       "                <div class=\"rnn-layer\">\n",
       "                    <div class=\"lstm-cell\">\n",
       "                        <div class=\"cell-state\">C₀: [0.0]</div>\n",
       "                        <div class=\"lstm-gate forget-gate\">Forget Gate</div>\n",
       "                        <div class=\"lstm-gate input-gate\">Input Gate</div>\n",
       "                        <div class=\"lstm-gate output-gate\">Output Gate</div>\n",
       "                        <div style=\"font-size: 12px; margin-top: 5px;\">LSTM 1</div>\n",
       "                    </div>\n",
       "                    <div class=\"rnn-arrow\"></div>\n",
       "                    <div class=\"lstm-cell\">\n",
       "                        <div class=\"cell-state\">C₁: [0.8]</div>\n",
       "                        <div class=\"lstm-gate forget-gate\">Forget Gate</div>\n",
       "                        <div class=\"lstm-gate input-gate\">Input Gate</div>\n",
       "                        <div class=\"lstm-gate output-gate\">Output Gate</div>\n",
       "                        <div style=\"font-size: 12px; margin-top: 5px;\">LSTM 2</div>\n",
       "                    </div>\n",
       "                    <div class=\"rnn-arrow\"></div>\n",
       "                    <div class=\"lstm-cell\">\n",
       "                        <div class=\"cell-state\">C₂: [0.7]</div>\n",
       "                        <div class=\"lstm-gate forget-gate\">Forget Gate</div>\n",
       "                        <div class=\"lstm-gate input-gate\">Input Gate</div>\n",
       "                        <div class=\"lstm-gate output-gate\">Output Gate</div>\n",
       "                        <div style=\"font-size: 12px; margin-top: 5px;\">LSTM 3</div>\n",
       "                    </div>\n",
       "                </div>\n",
       "\n",
       "                <div class=\"explanation\">\n",
       "                    <strong>Solution:</strong> C₂ still contains information about \"The\" because the cell state can flow through unchanged. Gates control what to remember/forget.<br>\n",
       "                    <strong>Gates:</strong>\n",
       "                    <span style=\"color: #e53e3e;\">Forget</span> (what to remove),\n",
       "                    <span style=\"color: #38a169;\">Input</span> (what to add),\n",
       "                    <span style=\"color: #3182ce;\">Output</span> (what to output)\n",
       "                </div>\n",
       "            </div>\n",
       "        </div>\n",
       "\n",
       "        <!-- Beam Search Detailed Section -->\n",
       "        <div class=\"diagram-section\">\n",
       "            <h2>2. Beam Search with Pruning (Beam Width = 3)</h2>\n",
       "            <div class=\"explanation\">\n",
       "                <strong>Goal:</strong> Translate \"Der Hund\" → \"The dog\". At each step, keep only the top 3 sequences and prune the rest.\n",
       "            </div>\n",
       "\n",
       "            <div class=\"beam-container\">\n",
       "                <!-- Step 1 -->\n",
       "                <div class=\"beam-step\">\n",
       "                    <div class=\"beam-header\">Step 1: Generate first word candidates</div>\n",
       "                    <div class=\"candidates-row\">\n",
       "                        <div class=\"candidate kept\">\n",
       "                            <div>\"The\"</div>\n",
       "                            <div class=\"score\">log_prob: -0.1</div>\n",
       "                        </div>\n",
       "                        <div class=\"candidate kept\">\n",
       "                            <div>\"A\"</div>\n",
       "                            <div class=\"score\">log_prob: -0.3</div>\n",
       "                        </div>\n",
       "                        <div class=\"candidate kept\">\n",
       "                            <div>\"This\"</div>\n",
       "                            <div class=\"score\">log_prob: -0.5</div>\n",
       "                        </div>\n",
       "                        <div class=\"candidate pruned\">\n",
       "                            <div>\"An\"</div>\n",
       "                            <div class=\"score\">log_prob: -0.8</div>\n",
       "                        </div>\n",
       "                        <div class=\"candidate pruned\">\n",
       "                            <div>\"My\"</div>\n",
       "                            <div class=\"score\">log_prob: -1.2</div>\n",
       "                        </div>\n",
       "                    </div>\n",
       "                    <div class=\"beam-width\">✂️ Pruned 2 candidates, kept top 3</div>\n",
       "                </div>\n",
       "\n",
       "                <!-- Step 2 -->\n",
       "                <div class=\"beam-step\">\n",
       "                    <div class=\"beam-header\">Step 2: Extend each kept sequence</div>\n",
       "                    <div style=\"margin: 10px 0; font-weight: bold;\">From \"The\" + next word:</div>\n",
       "                    <div class=\"candidates-row\">\n",
       "                        <div class=\"candidate kept\">\n",
       "                            <div>\"The dog\"</div>\n",
       "                            <div class=\"score\">log_prob: -0.3</div>\n",
       "                        </div>\n",
       "                        <div class=\"candidate\">\n",
       "                            <div>\"The cat\"</div>\n",
       "                            <div class=\"score\">log_prob: -0.6</div>\n",
       "                        </div>\n",
       "                        <div class=\"candidate\">\n",
       "                            <div>\"The man\"</div>\n",
       "                            <div class=\"score\">log_prob: -0.9</div>\n",
       "                        </div>\n",
       "                    </div>\n",
       "\n",
       "                    <div style=\"margin: 10px 0; font-weight: bold;\">From \"A\" + next word:</div>\n",
       "                    <div class=\"candidates-row\">\n",
       "                        <div class=\"candidate kept\">\n",
       "                            <div>\"A dog\"</div>\n",
       "                            <div class=\"score\">log_prob: -0.5</div>\n",
       "                        </div>\n",
       "                        <div class=\"candidate\">\n",
       "                            <div>\"A cat\"</div>\n",
       "                            <div class=\"score\">log_prob: -0.7</div>\n",
       "                        </div>\n",
       "                    </div>\n",
       "\n",
       "                    <div style=\"margin: 10px 0; font-weight: bold;\">From \"This\" + next word:</div>\n",
       "                    <div class=\"candidates-row\">\n",
       "                        <div class=\"candidate kept\">\n",
       "                            <div>\"This dog\"</div>\n",
       "                            <div class=\"score\">log_prob: -0.8</div>\n",
       "                        </div>\n",
       "                        <div class=\"candidate pruned\">\n",
       "                            <div>\"This cat\"</div>\n",
       "                            <div class=\"score\">log_prob: -1.0</div>\n",
       "                        </div>\n",
       "                    </div>\n",
       "\n",
       "                    <div class=\"beam-width\">✂️ Generated 6 candidates, kept top 3: \"The dog\", \"A dog\", \"This dog\"</div>\n",
       "                </div>\n",
       "\n",
       "                <!-- Step 3 -->\n",
       "                <div class=\"beam-step\">\n",
       "                    <div class=\"beam-header\">Step 3: Add END token</div>\n",
       "                    <div class=\"candidates-row\">\n",
       "                        <div class=\"candidate kept\">\n",
       "                            <div>\"The dog &lt;END&gt;\"</div>\n",
       "                            <div class=\"score\">log_prob: -0.4</div>\n",
       "                        </div>\n",
       "                        <div class=\"candidate\">\n",
       "                            <div>\"A dog &lt;END&gt;\"</div>\n",
       "                            <div class=\"score\">log_prob: -0.6</div>\n",
       "                        </div>\n",
       "                        <div class=\"candidate\">\n",
       "                            <div>\"This dog &lt;END&gt;\"</div>\n",
       "                            <div class=\"score\">log_prob: -0.9</div>\n",
       "                        </div>\n",
       "                    </div>\n",
       "                    <div class=\"pruning-explanation\">\n",
       "                        <strong>🏆 Winner:</strong> \"The dog\" with highest cumulative probability!<br>\n",
       "                        <strong>Key:</strong> Beam search found a better overall sequence than greedy (which might have picked \"A\" first)\n",
       "                    </div>\n",
       "                </div>\n",
       "            </div>\n",
       "\n",
       "            <button class=\"interactive-btn\" onclick=\"animateBeamPruning()\">🔄 Animate Pruning Process</button>\n",
       "        </div>\n",
       "\n",
       "        <!-- Transformer Output Section (keeping as requested) -->\n",
       "        <div class=\"diagram-section\">\n",
       "            <h2>3. Transformer Output Pipeline</h2>\n",
       "            <div class=\"explanation\">\n",
       "                <strong>From numbers to words:</strong> How the transformer converts internal calculations into actual text.\n",
       "            </div>\n",
       "\n",
       "            <div class=\"transformer-flow\">\n",
       "                <div class=\"flow-step\">\n",
       "                    <h4>🧠 Transformer Output</h4>\n",
       "                    <div style=\"font-family: monospace; background: rgba(255,255,255,0.2); padding: 10px; border-radius: 5px;\">\n",
       "                        Raw Logits: [2.3, -1.1, 4.7, 0.8, -0.3, ...]<br>\n",
       "                        <small>One number for each word in vocabulary (10,000+ words)</small>\n",
       "                    </div>\n",
       "                </div>\n",
       "\n",
       "                <div class=\"flow-arrow\"></div>\n",
       "\n",
       "                <div class=\"flow-step\">\n",
       "                    <h4>📊 Softmax Function</h4>\n",
       "                    <div>Converts raw numbers to probabilities</div>\n",
       "                    <div style=\"font-family: monospace; background: rgba(255,255,255,0.2); padding: 10px; border-radius: 5px; margin-top: 10px;\">\n",
       "                        Formula: P(word) = e^(logit) / Σ(e^(all_logits))\n",
       "                    </div>\n",
       "                </div>\n",
       "\n",
       "                <div class=\"flow-arrow\"></div>\n",
       "\n",
       "                <div class=\"flow-step\">\n",
       "                    <h4>📈 Probability Distribution</h4>\n",
       "                    <div class=\"word-example\">\n",
       "                        <div style=\"display: flex; justify-content: space-between; align-items: center; margin: 5px 0;\">\n",
       "                            <span>\"cat\"</span>\n",
       "                            <div class=\"probability-bar\" style=\"width: 150px;\">\n",
       "                                <div class=\"probability-fill\" style=\"width: 65%; background: linear-gradient(90deg, #51cf66, #40c057);\"></div>\n",
       "                            </div>\n",
       "                            <span>65%</span>\n",
       "                        </div>\n",
       "                        <div style=\"display: flex; justify-content: space-between; align-items: center; margin: 5px 0;\">\n",
       "                            <span>\"dog\"</span>\n",
       "                            <div class=\"probability-bar\" style=\"width: 150px;\">\n",
       "                                <div class=\"probability-fill\" style=\"width: 20%; background: linear-gradient(90deg, #ffd43b, #fab005);\"></div>\n",
       "                            </div>\n",
       "                            <span>20%</span>\n",
       "                        </div>\n",
       "                        <div style=\"display: flex; justify-content: space-between; align-items: center; margin: 5px 0;\">\n",
       "                            <span>\"bird\"</span>\n",
       "                            <div class=\"probability-bar\" style=\"width: 150px;\">\n",
       "                                <div class=\"probability-fill\" style=\"width: 10%; background: linear-gradient(90deg, #ff8787, #fa5252);\"></div>\n",
       "                            </div>\n",
       "                            <span>10%</span>\n",
       "                        </div>\n",
       "                        <div style=\"display: flex; justify-content: space-between; align-items: center; margin: 5px 0;\">\n",
       "                            <span>\"others\"</span>\n",
       "                            <div class=\"probability-bar\" style=\"width: 150px;\">\n",
       "                                <div class=\"probability-fill\" style=\"width: 5%; background: linear-gradient(90deg, #adb5bd, #868e96);\"></div>\n",
       "                            </div>\n",
       "                            <span>5%</span>\n",
       "                        </div>\n",
       "                    </div>\n",
       "                </div>\n",
       "\n",
       "                <div class=\"flow-arrow\"></div>\n",
       "\n",
       "                <div class=\"flow-step\">\n",
       "                    <h4>🎯 Final Word Selection</h4>\n",
       "                    <div style=\"font-size: 1.5em; color: #51cf66; font-weight: bold;\">\n",
       "                        Selected: \"cat\" ✓\n",
       "                    </div>\n",
       "                    <small>Usually picks highest probability (greedy)<br>or uses beam search for better results</small>\n",
       "                </div>\n",
       "            </div>\n",
       "\n",
       "            <button class=\"interactive-btn\" onclick=\"animateTransformerFlow()\">🔄 Show Different Predictions</button>\n",
       "        </div>\n",
       "\n",
       "        <!-- Key Differences Section (keeping as requested) -->\n",
       "        <div class=\"diagram-section\">\n",
       "            <h2>4. Key Takeaways</h2>\n",
       "            <div style=\"display: grid; grid-template-columns: 1fr 1fr; gap: 20px;\">\n",
       "                <div class=\"explanation\">\n",
       "                    <h4>🔄 RNN vs LSTM</h4>\n",
       "                    <strong>RNN:</strong> Information gets diluted through hidden states<br>\n",
       "                    <strong>LSTM:</strong> Cell state preserves long-term memory via gates\n",
       "                </div>\n",
       "                <div class=\"explanation\">\n",
       "                    <h4>🌳 Beam Search Pruning</h4>\n",
       "                    <strong>At each step:</strong> Generate all possibilities<br>\n",
       "                    <strong>Then prune:</strong> Keep only top-K to avoid exponential explosion\n",
       "                </div>\n",
       "                <div class=\"explanation\">\n",
       "                    <h4>🧮 Logits → Probabilities</h4>\n",
       "                    <strong>Logits:</strong> Raw math outputs (can be any number)<br>\n",
       "                    <strong>Softmax:</strong> Converts to percentages that add up to 100%\n",
       "                </div>\n",
       "                <div class=\"explanation\">\n",
       "                    <h4>🎯 Word Selection</h4>\n",
       "                    <strong>Deterministic:</strong> Always pick highest probability<br>\n",
       "                    <strong>Sampling:</strong> Sometimes pick lower probabilities for creativity\n",
       "                </div>\n",
       "            </div>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <script>\n",
       "        function animateBeamPruning() {\n",
       "            const steps = document.querySelectorAll('.beam-step');\n",
       "\n",
       "            steps.forEach((step, stepIndex) => {\n",
       "                setTimeout(() => {\n",
       "                    const candidates = step.querySelectorAll('.candidate');\n",
       "                    candidates.forEach((candidate, candIndex) => {\n",
       "                        setTimeout(() => {\n",
       "                            candidate.style.transform = 'scale(1.1)';\n",
       "                            candidate.style.opacity = '1';\n",
       "                            setTimeout(() => {\n",
       "                                candidate.style.transform = 'scale(1)';\n",
       "                                if (candidate.classList.contains('pruned')) {\n",
       "                                    candidate.style.opacity = '0.4';\n",
       "                                }\n",
       "                            }, 300);\n",
       "                        }, candIndex * 200);\n",
       "                    });\n",
       "                }, stepIndex * 1500);\n",
       "            });\n",
       "        }\n",
       "\n",
       "        function animateTransformerFlow() {\n",
       "            const examples = [\n",
       "                {\n",
       "                    logits: \"Raw Logits: [1.2, -2.1, 3.8, 0.5, -0.8, ...]\",\n",
       "                    words: [\n",
       "                        {word: \"dog\", prob: 45, color: \"#51cf66\"},\n",
       "                        {word: \"cat\", prob: 30, color: \"#ffd43b\"},\n",
       "                        {word: \"bird\", prob: 15, color: \"#ff8787\"},\n",
       "                        {word: \"others\", prob: 10, color: \"#adb5bd\"}\n",
       "                    ],\n",
       "                    selected: \"dog\"\n",
       "                },\n",
       "                {\n",
       "                    logits: \"Raw Logits: [4.1, 0.2, -1.5, 2.3, 1.1, ...]\",\n",
       "                    words: [\n",
       "                        {word: \"sits\", prob: 70, color: \"#51cf66\"},\n",
       "                        {word: \"runs\", prob: 15, color: \"#ffd43b\"},\n",
       "                        {word: \"jumps\", prob: 10, color: \"#ff8787\"},\n",
       "                        {word: \"others\", prob: 5, color: \"#adb5bd\"}\n",
       "                    ],\n",
       "                    selected: \"sits\"\n",
       "                }\n",
       "            ];\n",
       "\n",
       "            const currentExample = examples[Math.floor(Math.random() * examples.length)];\n",
       "\n",
       "            // Update logits\n",
       "            const logitsDisplay = document.querySelector('.flow-step div[style*=\"monospace\"]');\n",
       "            logitsDisplay.innerHTML = currentExample.logits + '<br><small>One number for each word in vocabulary (10,000+ words)</small>';\n",
       "\n",
       "            // Update probabilities\n",
       "            const wordExample = document.querySelector('.word-example');\n",
       "            wordExample.innerHTML = currentExample.words.map(item => `\n",
       "                <div style=\"display: flex; justify-content: space-between; align-items: center; margin: 5px 0;\">\n",
       "                    <span>\"${item.word}\"</span>\n",
       "                    <div class=\"probability-bar\" style=\"width: 150px;\">\n",
       "                        <div class=\"probability-fill\" style=\"width: ${item.prob}%; background: linear-gradient(90deg, ${item.color}, ${item.color});\"></div>\n",
       "                    </div>\n",
       "                    <span>${item.prob}%</span>\n",
       "                </div>\n",
       "            `).join('');\n",
       "\n",
       "            // Update selection\n",
       "            const selection = document.querySelector('.flow-step:last-child div[style*=\"font-size\"]');\n",
       "            selection.innerHTML = `Selected: \"${currentExample.selected}\" ✓`;\n",
       "        }\n",
       "    </script>\n",
       "</body>\n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "# Copy the entire HTML content and assign it to a variable\n",
    "html_content2 = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>ML Model Diagrams</title>\n",
    "    <style>\n",
    "        body {\n",
    "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "            margin: 0;\n",
    "            padding: 20px;\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            color: #333;\n",
    "        }\n",
    "\n",
    "        .container {\n",
    "            max-width: 1400px;\n",
    "            margin: 0 auto;\n",
    "        }\n",
    "\n",
    "        .diagram-section {\n",
    "            background: white;\n",
    "            border-radius: 15px;\n",
    "            padding: 30px;\n",
    "            margin: 30px 0;\n",
    "            box-shadow: 0 10px 30px rgba(0,0,0,0.1);\n",
    "        }\n",
    "\n",
    "        h1 {\n",
    "            text-align: center;\n",
    "            color: white;\n",
    "            font-size: 2.5em;\n",
    "            margin-bottom: 40px;\n",
    "            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);\n",
    "        }\n",
    "\n",
    "        h2 {\n",
    "            color: #4a5568;\n",
    "            border-bottom: 3px solid #667eea;\n",
    "            padding-bottom: 10px;\n",
    "            margin-bottom: 25px;\n",
    "        }\n",
    "\n",
    "        /* RNN Architecture */\n",
    "        .rnn-architecture {\n",
    "            display: flex;\n",
    "            flex-direction: column;\n",
    "            align-items: center;\n",
    "            margin: 40px 0;\n",
    "        }\n",
    "\n",
    "        .sequence-input {\n",
    "            display: flex;\n",
    "            gap: 20px;\n",
    "            margin-bottom: 30px;\n",
    "        }\n",
    "\n",
    "        .input-word {\n",
    "            background: #e3f2fd;\n",
    "            border: 2px solid #2196f3;\n",
    "            border-radius: 10px;\n",
    "            padding: 15px 20px;\n",
    "            font-weight: bold;\n",
    "            color: #1976d2;\n",
    "        }\n",
    "\n",
    "        .rnn-layer {\n",
    "            display: flex;\n",
    "            align-items: center;\n",
    "            gap: 20px;\n",
    "            margin: 20px 0;\n",
    "        }\n",
    "\n",
    "        .rnn-cell {\n",
    "            width: 100px;\n",
    "            height: 80px;\n",
    "            background: linear-gradient(45deg, #ff6b6b, #ee5a52);\n",
    "            border-radius: 15px;\n",
    "            display: flex;\n",
    "            flex-direction: column;\n",
    "            align-items: center;\n",
    "            justify-content: center;\n",
    "            color: white;\n",
    "            font-weight: bold;\n",
    "            position: relative;\n",
    "        }\n",
    "\n",
    "        .hidden-state {\n",
    "            position: absolute;\n",
    "            top: -40px;\n",
    "            background: #fff3e0;\n",
    "            border: 2px solid #ff9800;\n",
    "            border-radius: 8px;\n",
    "            padding: 5px 10px;\n",
    "            font-size: 12px;\n",
    "            color: #e65100;\n",
    "            font-weight: bold;\n",
    "        }\n",
    "\n",
    "        .rnn-arrow {\n",
    "            width: 40px;\n",
    "            height: 3px;\n",
    "            background: #4a5568;\n",
    "            position: relative;\n",
    "        }\n",
    "\n",
    "        .rnn-arrow::after {\n",
    "            content: '';\n",
    "            position: absolute;\n",
    "            right: -8px;\n",
    "            top: -5px;\n",
    "            width: 0;\n",
    "            height: 0;\n",
    "            border-left: 12px solid #4a5568;\n",
    "            border-top: 6px solid transparent;\n",
    "            border-bottom: 6px solid transparent;\n",
    "        }\n",
    "\n",
    "        .vertical-arrow {\n",
    "            width: 3px;\n",
    "            height: 30px;\n",
    "            background: #4a5568;\n",
    "            position: relative;\n",
    "            margin: 10px auto;\n",
    "        }\n",
    "\n",
    "        .vertical-arrow::after {\n",
    "            content: '';\n",
    "            position: absolute;\n",
    "            bottom: -8px;\n",
    "            left: -5px;\n",
    "            width: 0;\n",
    "            height: 0;\n",
    "            border-top: 12px solid #4a5568;\n",
    "            border-left: 6px solid transparent;\n",
    "            border-right: 6px solid transparent;\n",
    "        }\n",
    "\n",
    "        /* LSTM Architecture */\n",
    "        .lstm-cell {\n",
    "            width: 140px;\n",
    "            height: 120px;\n",
    "            background: linear-gradient(45deg, #4ecdc4, #44a08d);\n",
    "            border-radius: 20px;\n",
    "            display: flex;\n",
    "            flex-direction: column;\n",
    "            align-items: center;\n",
    "            justify-content: space-around;\n",
    "            color: white;\n",
    "            font-weight: bold;\n",
    "            position: relative;\n",
    "            padding: 10px;\n",
    "        }\n",
    "\n",
    "        .lstm-gate {\n",
    "            background: rgba(255,255,255,0.3);\n",
    "            border-radius: 8px;\n",
    "            padding: 5px 8px;\n",
    "            font-size: 10px;\n",
    "            margin: 2px 0;\n",
    "            text-align: center;\n",
    "        }\n",
    "\n",
    "        .forget-gate { background: rgba(255,87,87,0.8); }\n",
    "        .input-gate { background: rgba(72,187,120,0.8); }\n",
    "        .output-gate { background: rgba(66,153,225,0.8); }\n",
    "\n",
    "        .cell-state {\n",
    "            position: absolute;\n",
    "            top: -50px;\n",
    "            left: 50%;\n",
    "            transform: translateX(-50%);\n",
    "            background: #ffd54f;\n",
    "            border: 3px solid #ff8f00;\n",
    "            border-radius: 10px;\n",
    "            padding: 8px 12px;\n",
    "            font-size: 12px;\n",
    "            color: #e65100;\n",
    "            font-weight: bold;\n",
    "        }\n",
    "\n",
    "        /* Beam Search Detailed */\n",
    "        .beam-container {\n",
    "            margin: 40px 0;\n",
    "        }\n",
    "\n",
    "        .beam-step {\n",
    "            margin: 30px 0;\n",
    "            padding: 20px;\n",
    "            border: 2px solid #e2e8f0;\n",
    "            border-radius: 15px;\n",
    "            background: #f8f9fa;\n",
    "        }\n",
    "\n",
    "        .beam-header {\n",
    "            font-weight: bold;\n",
    "            color: #2d3748;\n",
    "            margin-bottom: 15px;\n",
    "            font-size: 18px;\n",
    "        }\n",
    "\n",
    "        .candidates-row {\n",
    "            display: flex;\n",
    "            gap: 15px;\n",
    "            margin: 15px 0;\n",
    "            flex-wrap: wrap;\n",
    "        }\n",
    "\n",
    "        .candidate {\n",
    "            background: linear-gradient(45deg, #667eea, #764ba2);\n",
    "            color: white;\n",
    "            padding: 12px 15px;\n",
    "            border-radius: 12px;\n",
    "            min-width: 120px;\n",
    "            text-align: center;\n",
    "            position: relative;\n",
    "        }\n",
    "\n",
    "        .candidate.kept {\n",
    "            background: linear-gradient(45deg, #48bb78, #38a169);\n",
    "            border: 3px solid #22543d;\n",
    "        }\n",
    "\n",
    "        .candidate.pruned {\n",
    "            background: linear-gradient(45deg, #e53e3e, #c53030);\n",
    "            opacity: 0.6;\n",
    "            text-decoration: line-through;\n",
    "        }\n",
    "\n",
    "        .score {\n",
    "            font-size: 11px;\n",
    "            opacity: 0.9;\n",
    "            margin-top: 5px;\n",
    "        }\n",
    "\n",
    "        .beam-width {\n",
    "            background: #fed7d7;\n",
    "            border: 2px solid #e53e3e;\n",
    "            border-radius: 10px;\n",
    "            padding: 10px;\n",
    "            margin: 15px 0;\n",
    "            text-align: center;\n",
    "            font-weight: bold;\n",
    "            color: #c53030;\n",
    "        }\n",
    "\n",
    "        .pruning-explanation {\n",
    "            background: #bee3f8;\n",
    "            border: 2px solid #3182ce;\n",
    "            border-radius: 10px;\n",
    "            padding: 15px;\n",
    "            margin: 15px 0;\n",
    "            color: #2a69ac;\n",
    "        }\n",
    "\n",
    "        /* Interactive elements */\n",
    "        .interactive-btn {\n",
    "            background: linear-gradient(45deg, #667eea, #764ba2);\n",
    "            color: white;\n",
    "            border: none;\n",
    "            padding: 12px 25px;\n",
    "            border-radius: 25px;\n",
    "            cursor: pointer;\n",
    "            font-weight: bold;\n",
    "            margin: 10px;\n",
    "            transition: transform 0.2s;\n",
    "            font-size: 16px;\n",
    "        }\n",
    "\n",
    "        .interactive-btn:hover {\n",
    "            transform: translateY(-2px);\n",
    "        }\n",
    "\n",
    "        /* Transformer Flow (keeping as is) */\n",
    "        .transformer-flow {\n",
    "            display: flex;\n",
    "            flex-direction: column;\n",
    "            align-items: center;\n",
    "            gap: 30px;\n",
    "        }\n",
    "\n",
    "        .flow-step {\n",
    "            background: linear-gradient(45deg, #667eea, #764ba2);\n",
    "            color: white;\n",
    "            padding: 20px;\n",
    "            border-radius: 15px;\n",
    "            text-align: center;\n",
    "            min-width: 200px;\n",
    "            position: relative;\n",
    "        }\n",
    "\n",
    "        .flow-arrow {\n",
    "            width: 0;\n",
    "            height: 0;\n",
    "            border-left: 15px solid transparent;\n",
    "            border-right: 15px solid transparent;\n",
    "            border-top: 20px solid #667eea;\n",
    "            margin: -5px auto;\n",
    "        }\n",
    "\n",
    "        .probability-bar {\n",
    "            background: #e2e8f0;\n",
    "            height: 20px;\n",
    "            border-radius: 10px;\n",
    "            margin: 10px 0;\n",
    "            overflow: hidden;\n",
    "            position: relative;\n",
    "        }\n",
    "\n",
    "        .probability-fill {\n",
    "            height: 100%;\n",
    "            border-radius: 10px;\n",
    "            transition: width 0.5s ease;\n",
    "        }\n",
    "\n",
    "        .word-example {\n",
    "            background: #f7fafc;\n",
    "            border: 2px solid #e2e8f0;\n",
    "            border-radius: 10px;\n",
    "            padding: 15px;\n",
    "            margin: 20px 0;\n",
    "        }\n",
    "\n",
    "        .explanation {\n",
    "            background: #f8f9fa;\n",
    "            border-left: 4px solid #667eea;\n",
    "            padding: 15px;\n",
    "            margin: 20px 0;\n",
    "            border-radius: 0 10px 10px 0;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"container\">\n",
    "        <h1>🤖 AI Model Architecture Deep Dive</h1>\n",
    "\n",
    "        <!-- RNN Architecture Section -->\n",
    "        <div class=\"diagram-section\">\n",
    "            <h2>1A. RNN (Recurrent Neural Network) Architecture</h2>\n",
    "            <div class=\"explanation\">\n",
    "                <strong>Key Challenge:</strong> Information from early words gets \"forgotten\" as the sequence progresses. The hidden state gets overwritten at each step.\n",
    "            </div>\n",
    "\n",
    "            <div class=\"rnn-architecture\">\n",
    "                <div class=\"sequence-input\">\n",
    "                    <div class=\"input-word\">x₁: \"The\"</div>\n",
    "                    <div class=\"input-word\">x₂: \"cat\"</div>\n",
    "                    <div class=\"input-word\">x₃: \"sat\"</div>\n",
    "                </div>\n",
    "\n",
    "                <div class=\"vertical-arrow\"></div>\n",
    "\n",
    "                <div class=\"rnn-layer\">\n",
    "                    <div class=\"rnn-cell\">\n",
    "                        <div class=\"hidden-state\">h₀: [0.0]</div>\n",
    "                        <div>RNN</div>\n",
    "                        <div style=\"font-size: 12px;\">Cell 1</div>\n",
    "                    </div>\n",
    "                    <div class=\"rnn-arrow\"></div>\n",
    "                    <div class=\"rnn-cell\">\n",
    "                        <div class=\"hidden-state\">h₁: [0.3]</div>\n",
    "                        <div>RNN</div>\n",
    "                        <div style=\"font-size: 12px;\">Cell 2</div>\n",
    "                    </div>\n",
    "                    <div class=\"rnn-arrow\"></div>\n",
    "                    <div class=\"rnn-cell\">\n",
    "                        <div class=\"hidden-state\">h₂: [0.1]</div>\n",
    "                        <div>RNN</div>\n",
    "                        <div style=\"font-size: 12px;\">Cell 3</div>\n",
    "                    </div>\n",
    "                </div>\n",
    "\n",
    "                <div class=\"explanation\">\n",
    "                    <strong>Problem:</strong> h₂ has very little information about \"The\" (the first word) because it gets diluted through multiple transformations. <br>\n",
    "                    <strong>Formula:</strong> h₂ = tanh(W·[x₂, h₁]) where h₁ = tanh(W·[x₁, h₀])\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "\n",
    "        <!-- RNN Cell Internal Section -->\n",
    "        <div class=\"diagram-section\">\n",
    "            <h2>1B. Inside an RNN Cell</h2>\n",
    "            <div class=\"explanation\">\n",
    "                <strong>What happens inside:</strong> Simple mathematical operations that blend current input with previous memory.\n",
    "            </div>\n",
    "\n",
    "            <div style=\"display: flex; justify-content: center; align-items: center; margin: 40px 0;\">\n",
    "                <div style=\"background: #f8f9fa; border: 3px solid #667eea; border-radius: 20px; padding: 30px; position: relative; width: 400px;\">\n",
    "                    <!-- Input arrows -->\n",
    "                    <div style=\"position: absolute; top: -40px; left: 50px; text-align: center;\">\n",
    "                        <div style=\"background: #e3f2fd; border: 2px solid #2196f3; border-radius: 8px; padding: 8px 12px; font-weight: bold; color: #1976d2;\">x_t</div>\n",
    "                        <div class=\"vertical-arrow\" style=\"height: 20px; margin: 5px auto;\"></div>\n",
    "                    </div>\n",
    "                    <div style=\"position: absolute; top: -40px; right: 50px; text-align: center;\">\n",
    "                        <div style=\"background: #fff3e0; border: 2px solid #ff9800; border-radius: 8px; padding: 8px 12px; font-weight: bold; color: #e65100;\">h_{t-1}</div>\n",
    "                        <div class=\"vertical-arrow\" style=\"height: 20px; margin: 5px auto;\"></div>\n",
    "                    </div>\n",
    "\n",
    "                    <!-- Internal computation -->\n",
    "                    <div style=\"text-align: center; margin: 20px 0;\">\n",
    "                        <div style=\"background: #e8f5e8; border: 2px solid #4caf50; border-radius: 12px; padding: 15px; margin: 10px 0;\">\n",
    "                            <strong>Step 1: Combine Inputs</strong><br>\n",
    "                            <code style=\"background: white; padding: 5px; border-radius: 5px;\">combined = W_x * x_t + W_h * h_{t-1} + b</code>\n",
    "                        </div>\n",
    "                        <div style=\"background: #fff3e0; border: 2px solid #ff9800; border-radius: 12px; padding: 15px; margin: 10px 0;\">\n",
    "                            <strong>Step 2: Activation</strong><br>\n",
    "                            <code style=\"background: white; padding: 5px; border-radius: 5px;\">h_t = tanh(combined)</code>\n",
    "                        </div>\n",
    "                    </div>\n",
    "\n",
    "                    <!-- Output arrow -->\n",
    "                    <div style=\"position: absolute; bottom: -40px; left: 50%; transform: translateX(-50%); text-align: center;\">\n",
    "                        <div class=\"vertical-arrow\" style=\"height: 20px; margin: 5px auto; transform: rotate(180deg);\"></div>\n",
    "                        <div style=\"background: #fff3e0; border: 2px solid #ff9800; border-radius: 8px; padding: 8px 12px; font-weight: bold; color: #e65100;\">h_t</div>\n",
    "                    </div>\n",
    "                </div>\n",
    "            </div>\n",
    "\n",
    "            <div class=\"explanation\">\n",
    "                <strong>Problem:</strong> The same hidden state h_t serves as both memory and output. As sequences get longer, early information gets \"overwritten\" by newer information.\n",
    "            </div>\n",
    "        </div>\n",
    "\n",
    "        <!-- LSTM Cell Internal Section -->\n",
    "        <div class=\"diagram-section\">\n",
    "            <h2>1C. Inside an LSTM Cell</h2>\n",
    "            <div class=\"explanation\">\n",
    "                <strong>Key Innovation:</strong> Separate cell state (C_t) for long-term memory and hidden state (h_t) for output. Gates control information flow.\n",
    "            </div>\n",
    "\n",
    "            <div style=\"display: flex; justify-content: center; align-items: center; margin: 40px 0;\">\n",
    "                <div style=\"background: #f8f9fa; border: 3px solid #4ecdc4; border-radius: 20px; padding: 30px; position: relative; width: 500px; height: 400px;\">\n",
    "                    <!-- Inputs -->\n",
    "                    <div style=\"position: absolute; top: -40px; left: 100px; text-align: center;\">\n",
    "                        <div style=\"background: #e3f2fd; border: 2px solid #2196f3; border-radius: 8px; padding: 8px 12px; font-weight: bold; color: #1976d2;\">x_t</div>\n",
    "                        <div class=\"vertical-arrow\" style=\"height: 20px; margin: 5px auto;\"></div>\n",
    "                    </div>\n",
    "                    <div style=\"position: absolute; top: -40px; right: 100px; text-align: center;\">\n",
    "                        <div style=\"background: #fff3e0; border: 2px solid #ff9800; border-radius: 8px; padding: 8px 12px; font-weight: bold; color: #e65100;\">h_{t-1}</div>\n",
    "                        <div class=\"vertical-arrow\" style=\"height: 20px; margin: 5px auto;\"></div>\n",
    "                    </div>\n",
    "\n",
    "                    <!-- Cell state flow (top) -->\n",
    "                    <div style=\"position: absolute; top: 10px; left: 20px; right: 20px; display: flex; align-items: center;\">\n",
    "                        <div style=\"background: #ffd54f; border: 2px solid #ff8f00; border-radius: 8px; padding: 5px 10px; font-size: 12px; font-weight: bold;\">C_{t-1}</div>\n",
    "                        <div style=\"flex: 1; height: 3px; background: #ff8f00; margin: 0 10px; position: relative;\">\n",
    "                            <div style=\"position: absolute; right: -5px; top: -5px; width: 0; height: 0; border-left: 10px solid #ff8f00; border-top: 5px solid transparent; border-bottom: 5px solid transparent;\"></div>\n",
    "                        </div>\n",
    "                        <div style=\"background: #ffd54f; border: 2px solid #ff8f00; border-radius: 8px; padding: 5px 10px; font-size: 12px; font-weight: bold;\">C_t</div>\n",
    "                    </div>\n",
    "\n",
    "                    <!-- Gates (middle section) -->\n",
    "                    <div style=\"margin-top: 60px; display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 15px; text-align: center;\">\n",
    "                        <!-- Forget Gate -->\n",
    "                        <div style=\"background: rgba(255,87,87,0.8); border-radius: 12px; padding: 10px; color: white;\">\n",
    "                            <div style=\"font-weight: bold; font-size: 14px;\">Forget Gate</div>\n",
    "                            <div style=\"font-size: 10px; margin: 5px 0;\">f_t = σ(W_f[h_{t-1}, x_t])</div>\n",
    "                            <div style=\"font-size: 12px;\">What to forget?</div>\n",
    "                        </div>\n",
    "\n",
    "                        <!-- Input Gate -->\n",
    "                        <div style=\"background: rgba(72,187,120,0.8); border-radius: 12px; padding: 10px; color: white;\">\n",
    "                            <div style=\"font-weight: bold; font-size: 14px;\">Input Gate</div>\n",
    "                            <div style=\"font-size: 10px; margin: 5px 0;\">i_t = σ(W_i[h_{t-1}, x_t])</div>\n",
    "                            <div style=\"font-size: 12px;\">What to store?</div>\n",
    "                        </div>\n",
    "\n",
    "                        <!-- Output Gate -->\n",
    "                        <div style=\"background: rgba(66,153,225,0.8); border-radius: 12px; padding: 10px; color: white;\">\n",
    "                            <div style=\"font-weight: bold; font-size: 14px;\">Output Gate</div>\n",
    "                            <div style=\"font-size: 10px; margin: 5px 0;\">o_t = σ(W_o[h_{t-1}, x_t])</div>\n",
    "                            <div style=\"font-size: 12px;\">What to output?</div>\n",
    "                        </div>\n",
    "                    </div>\n",
    "\n",
    "                    <!-- Cell state update -->\n",
    "                    <div style=\"margin-top: 20px; text-align: center;\">\n",
    "                        <div style=\"background: #e8f5e8; border: 2px solid #4caf50; border-radius: 12px; padding: 10px; font-size: 12px;\">\n",
    "                            <strong>Cell State Update:</strong><br>\n",
    "                            <code style=\"background: white; padding: 3px; border-radius: 3px;\">C_t = f_t ⊙ C_{t-1} + i_t ⊙ tanh(W_c[h_{t-1}, x_t])</code>\n",
    "                        </div>\n",
    "                    </div>\n",
    "\n",
    "                    <!-- Hidden state output -->\n",
    "                    <div style=\"margin-top: 15px; text-align: center;\">\n",
    "                        <div style=\"background: #fff3e0; border: 2px solid #ff9800; border-radius: 12px; padding: 10px; font-size: 12px;\">\n",
    "                            <strong>Hidden State:</strong><br>\n",
    "                            <code style=\"background: white; padding: 3px; border-radius: 3px;\">h_t = o_t ⊙ tanh(C_t)</code>\n",
    "                        </div>\n",
    "                    </div>\n",
    "\n",
    "                    <!-- Output -->\n",
    "                    <div style=\"position: absolute; bottom: -40px; left: 50%; transform: translateX(-50%); text-align: center;\">\n",
    "                        <div class=\"vertical-arrow\" style=\"height: 20px; margin: 5px auto; transform: rotate(180deg);\"></div>\n",
    "                        <div style=\"background: #fff3e0; border: 2px solid #ff9800; border-radius: 8px; padding: 8px 12px; font-weight: bold; color: #e65100;\">h_t</div>\n",
    "                    </div>\n",
    "                </div>\n",
    "            </div>\n",
    "\n",
    "            <div class=\"explanation\">\n",
    "                <strong>Key Symbols:</strong> σ = sigmoid function (0-1), ⊙ = element-wise multiplication, tanh = hyperbolic tangent (-1 to 1)<br>\n",
    "                <strong>Solution:</strong> Cell state C_t flows through with minimal changes, preserving long-term information while gates control what gets added, removed, or output.\n",
    "            </div>\n",
    "        </div>\n",
    "\n",
    "        <!-- LSTM Architecture Section -->\n",
    "        <div class=\"diagram-section\">\n",
    "            <h2>1D. LSTM (Long Short-Term Memory) Architecture</h2>\n",
    "            <div class=\"explanation\">\n",
    "                <strong>Key Innovation:</strong> Separate cell state (C) flows through unchanged unless gates decide to modify it. This preserves long-term information.\n",
    "            </div>\n",
    "\n",
    "            <div class=\"rnn-architecture\">\n",
    "                <div class=\"sequence-input\">\n",
    "                    <div class=\"input-word\">x₁: \"The\"</div>\n",
    "                    <div class=\"input-word\">x₂: \"cat\"</div>\n",
    "                    <div class=\"input-word\">x₃: \"sat\"</div>\n",
    "                </div>\n",
    "\n",
    "                <div class=\"vertical-arrow\"></div>\n",
    "\n",
    "                <div class=\"rnn-layer\">\n",
    "                    <div class=\"lstm-cell\">\n",
    "                        <div class=\"cell-state\">C₀: [0.0]</div>\n",
    "                        <div class=\"lstm-gate forget-gate\">Forget Gate</div>\n",
    "                        <div class=\"lstm-gate input-gate\">Input Gate</div>\n",
    "                        <div class=\"lstm-gate output-gate\">Output Gate</div>\n",
    "                        <div style=\"font-size: 12px; margin-top: 5px;\">LSTM 1</div>\n",
    "                    </div>\n",
    "                    <div class=\"rnn-arrow\"></div>\n",
    "                    <div class=\"lstm-cell\">\n",
    "                        <div class=\"cell-state\">C₁: [0.8]</div>\n",
    "                        <div class=\"lstm-gate forget-gate\">Forget Gate</div>\n",
    "                        <div class=\"lstm-gate input-gate\">Input Gate</div>\n",
    "                        <div class=\"lstm-gate output-gate\">Output Gate</div>\n",
    "                        <div style=\"font-size: 12px; margin-top: 5px;\">LSTM 2</div>\n",
    "                    </div>\n",
    "                    <div class=\"rnn-arrow\"></div>\n",
    "                    <div class=\"lstm-cell\">\n",
    "                        <div class=\"cell-state\">C₂: [0.7]</div>\n",
    "                        <div class=\"lstm-gate forget-gate\">Forget Gate</div>\n",
    "                        <div class=\"lstm-gate input-gate\">Input Gate</div>\n",
    "                        <div class=\"lstm-gate output-gate\">Output Gate</div>\n",
    "                        <div style=\"font-size: 12px; margin-top: 5px;\">LSTM 3</div>\n",
    "                    </div>\n",
    "                </div>\n",
    "\n",
    "                <div class=\"explanation\">\n",
    "                    <strong>Solution:</strong> C₂ still contains information about \"The\" because the cell state can flow through unchanged. Gates control what to remember/forget.<br>\n",
    "                    <strong>Gates:</strong>\n",
    "                    <span style=\"color: #e53e3e;\">Forget</span> (what to remove),\n",
    "                    <span style=\"color: #38a169;\">Input</span> (what to add),\n",
    "                    <span style=\"color: #3182ce;\">Output</span> (what to output)\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "\n",
    "        <!-- Beam Search Detailed Section -->\n",
    "        <div class=\"diagram-section\">\n",
    "            <h2>2. Beam Search with Pruning (Beam Width = 3)</h2>\n",
    "            <div class=\"explanation\">\n",
    "                <strong>Goal:</strong> Translate \"Der Hund\" → \"The dog\". At each step, keep only the top 3 sequences and prune the rest.\n",
    "            </div>\n",
    "\n",
    "            <div class=\"beam-container\">\n",
    "                <!-- Step 1 -->\n",
    "                <div class=\"beam-step\">\n",
    "                    <div class=\"beam-header\">Step 1: Generate first word candidates</div>\n",
    "                    <div class=\"candidates-row\">\n",
    "                        <div class=\"candidate kept\">\n",
    "                            <div>\"The\"</div>\n",
    "                            <div class=\"score\">log_prob: -0.1</div>\n",
    "                        </div>\n",
    "                        <div class=\"candidate kept\">\n",
    "                            <div>\"A\"</div>\n",
    "                            <div class=\"score\">log_prob: -0.3</div>\n",
    "                        </div>\n",
    "                        <div class=\"candidate kept\">\n",
    "                            <div>\"This\"</div>\n",
    "                            <div class=\"score\">log_prob: -0.5</div>\n",
    "                        </div>\n",
    "                        <div class=\"candidate pruned\">\n",
    "                            <div>\"An\"</div>\n",
    "                            <div class=\"score\">log_prob: -0.8</div>\n",
    "                        </div>\n",
    "                        <div class=\"candidate pruned\">\n",
    "                            <div>\"My\"</div>\n",
    "                            <div class=\"score\">log_prob: -1.2</div>\n",
    "                        </div>\n",
    "                    </div>\n",
    "                    <div class=\"beam-width\">✂️ Pruned 2 candidates, kept top 3</div>\n",
    "                </div>\n",
    "\n",
    "                <!-- Step 2 -->\n",
    "                <div class=\"beam-step\">\n",
    "                    <div class=\"beam-header\">Step 2: Extend each kept sequence</div>\n",
    "                    <div style=\"margin: 10px 0; font-weight: bold;\">From \"The\" + next word:</div>\n",
    "                    <div class=\"candidates-row\">\n",
    "                        <div class=\"candidate kept\">\n",
    "                            <div>\"The dog\"</div>\n",
    "                            <div class=\"score\">log_prob: -0.3</div>\n",
    "                        </div>\n",
    "                        <div class=\"candidate\">\n",
    "                            <div>\"The cat\"</div>\n",
    "                            <div class=\"score\">log_prob: -0.6</div>\n",
    "                        </div>\n",
    "                        <div class=\"candidate\">\n",
    "                            <div>\"The man\"</div>\n",
    "                            <div class=\"score\">log_prob: -0.9</div>\n",
    "                        </div>\n",
    "                    </div>\n",
    "\n",
    "                    <div style=\"margin: 10px 0; font-weight: bold;\">From \"A\" + next word:</div>\n",
    "                    <div class=\"candidates-row\">\n",
    "                        <div class=\"candidate kept\">\n",
    "                            <div>\"A dog\"</div>\n",
    "                            <div class=\"score\">log_prob: -0.5</div>\n",
    "                        </div>\n",
    "                        <div class=\"candidate\">\n",
    "                            <div>\"A cat\"</div>\n",
    "                            <div class=\"score\">log_prob: -0.7</div>\n",
    "                        </div>\n",
    "                    </div>\n",
    "\n",
    "                    <div style=\"margin: 10px 0; font-weight: bold;\">From \"This\" + next word:</div>\n",
    "                    <div class=\"candidates-row\">\n",
    "                        <div class=\"candidate kept\">\n",
    "                            <div>\"This dog\"</div>\n",
    "                            <div class=\"score\">log_prob: -0.8</div>\n",
    "                        </div>\n",
    "                        <div class=\"candidate pruned\">\n",
    "                            <div>\"This cat\"</div>\n",
    "                            <div class=\"score\">log_prob: -1.0</div>\n",
    "                        </div>\n",
    "                    </div>\n",
    "\n",
    "                    <div class=\"beam-width\">✂️ Generated 6 candidates, kept top 3: \"The dog\", \"A dog\", \"This dog\"</div>\n",
    "                </div>\n",
    "\n",
    "                <!-- Step 3 -->\n",
    "                <div class=\"beam-step\">\n",
    "                    <div class=\"beam-header\">Step 3: Add END token</div>\n",
    "                    <div class=\"candidates-row\">\n",
    "                        <div class=\"candidate kept\">\n",
    "                            <div>\"The dog &lt;END&gt;\"</div>\n",
    "                            <div class=\"score\">log_prob: -0.4</div>\n",
    "                        </div>\n",
    "                        <div class=\"candidate\">\n",
    "                            <div>\"A dog &lt;END&gt;\"</div>\n",
    "                            <div class=\"score\">log_prob: -0.6</div>\n",
    "                        </div>\n",
    "                        <div class=\"candidate\">\n",
    "                            <div>\"This dog &lt;END&gt;\"</div>\n",
    "                            <div class=\"score\">log_prob: -0.9</div>\n",
    "                        </div>\n",
    "                    </div>\n",
    "                    <div class=\"pruning-explanation\">\n",
    "                        <strong>🏆 Winner:</strong> \"The dog\" with highest cumulative probability!<br>\n",
    "                        <strong>Key:</strong> Beam search found a better overall sequence than greedy (which might have picked \"A\" first)\n",
    "                    </div>\n",
    "                </div>\n",
    "            </div>\n",
    "\n",
    "            <button class=\"interactive-btn\" onclick=\"animateBeamPruning()\">🔄 Animate Pruning Process</button>\n",
    "        </div>\n",
    "\n",
    "        <!-- Transformer Output Section (keeping as requested) -->\n",
    "        <div class=\"diagram-section\">\n",
    "            <h2>3. Transformer Output Pipeline</h2>\n",
    "            <div class=\"explanation\">\n",
    "                <strong>From numbers to words:</strong> How the transformer converts internal calculations into actual text.\n",
    "            </div>\n",
    "\n",
    "            <div class=\"transformer-flow\">\n",
    "                <div class=\"flow-step\">\n",
    "                    <h4>🧠 Transformer Output</h4>\n",
    "                    <div style=\"font-family: monospace; background: rgba(255,255,255,0.2); padding: 10px; border-radius: 5px;\">\n",
    "                        Raw Logits: [2.3, -1.1, 4.7, 0.8, -0.3, ...]<br>\n",
    "                        <small>One number for each word in vocabulary (10,000+ words)</small>\n",
    "                    </div>\n",
    "                </div>\n",
    "\n",
    "                <div class=\"flow-arrow\"></div>\n",
    "\n",
    "                <div class=\"flow-step\">\n",
    "                    <h4>📊 Softmax Function</h4>\n",
    "                    <div>Converts raw numbers to probabilities</div>\n",
    "                    <div style=\"font-family: monospace; background: rgba(255,255,255,0.2); padding: 10px; border-radius: 5px; margin-top: 10px;\">\n",
    "                        Formula: P(word) = e^(logit) / Σ(e^(all_logits))\n",
    "                    </div>\n",
    "                </div>\n",
    "\n",
    "                <div class=\"flow-arrow\"></div>\n",
    "\n",
    "                <div class=\"flow-step\">\n",
    "                    <h4>📈 Probability Distribution</h4>\n",
    "                    <div class=\"word-example\">\n",
    "                        <div style=\"display: flex; justify-content: space-between; align-items: center; margin: 5px 0;\">\n",
    "                            <span>\"cat\"</span>\n",
    "                            <div class=\"probability-bar\" style=\"width: 150px;\">\n",
    "                                <div class=\"probability-fill\" style=\"width: 65%; background: linear-gradient(90deg, #51cf66, #40c057);\"></div>\n",
    "                            </div>\n",
    "                            <span>65%</span>\n",
    "                        </div>\n",
    "                        <div style=\"display: flex; justify-content: space-between; align-items: center; margin: 5px 0;\">\n",
    "                            <span>\"dog\"</span>\n",
    "                            <div class=\"probability-bar\" style=\"width: 150px;\">\n",
    "                                <div class=\"probability-fill\" style=\"width: 20%; background: linear-gradient(90deg, #ffd43b, #fab005);\"></div>\n",
    "                            </div>\n",
    "                            <span>20%</span>\n",
    "                        </div>\n",
    "                        <div style=\"display: flex; justify-content: space-between; align-items: center; margin: 5px 0;\">\n",
    "                            <span>\"bird\"</span>\n",
    "                            <div class=\"probability-bar\" style=\"width: 150px;\">\n",
    "                                <div class=\"probability-fill\" style=\"width: 10%; background: linear-gradient(90deg, #ff8787, #fa5252);\"></div>\n",
    "                            </div>\n",
    "                            <span>10%</span>\n",
    "                        </div>\n",
    "                        <div style=\"display: flex; justify-content: space-between; align-items: center; margin: 5px 0;\">\n",
    "                            <span>\"others\"</span>\n",
    "                            <div class=\"probability-bar\" style=\"width: 150px;\">\n",
    "                                <div class=\"probability-fill\" style=\"width: 5%; background: linear-gradient(90deg, #adb5bd, #868e96);\"></div>\n",
    "                            </div>\n",
    "                            <span>5%</span>\n",
    "                        </div>\n",
    "                    </div>\n",
    "                </div>\n",
    "\n",
    "                <div class=\"flow-arrow\"></div>\n",
    "\n",
    "                <div class=\"flow-step\">\n",
    "                    <h4>🎯 Final Word Selection</h4>\n",
    "                    <div style=\"font-size: 1.5em; color: #51cf66; font-weight: bold;\">\n",
    "                        Selected: \"cat\" ✓\n",
    "                    </div>\n",
    "                    <small>Usually picks highest probability (greedy)<br>or uses beam search for better results</small>\n",
    "                </div>\n",
    "            </div>\n",
    "\n",
    "            <button class=\"interactive-btn\" onclick=\"animateTransformerFlow()\">🔄 Show Different Predictions</button>\n",
    "        </div>\n",
    "\n",
    "        <!-- Key Differences Section (keeping as requested) -->\n",
    "        <div class=\"diagram-section\">\n",
    "            <h2>4. Key Takeaways</h2>\n",
    "            <div style=\"display: grid; grid-template-columns: 1fr 1fr; gap: 20px;\">\n",
    "                <div class=\"explanation\">\n",
    "                    <h4>🔄 RNN vs LSTM</h4>\n",
    "                    <strong>RNN:</strong> Information gets diluted through hidden states<br>\n",
    "                    <strong>LSTM:</strong> Cell state preserves long-term memory via gates\n",
    "                </div>\n",
    "                <div class=\"explanation\">\n",
    "                    <h4>🌳 Beam Search Pruning</h4>\n",
    "                    <strong>At each step:</strong> Generate all possibilities<br>\n",
    "                    <strong>Then prune:</strong> Keep only top-K to avoid exponential explosion\n",
    "                </div>\n",
    "                <div class=\"explanation\">\n",
    "                    <h4>🧮 Logits → Probabilities</h4>\n",
    "                    <strong>Logits:</strong> Raw math outputs (can be any number)<br>\n",
    "                    <strong>Softmax:</strong> Converts to percentages that add up to 100%\n",
    "                </div>\n",
    "                <div class=\"explanation\">\n",
    "                    <h4>🎯 Word Selection</h4>\n",
    "                    <strong>Deterministic:</strong> Always pick highest probability<br>\n",
    "                    <strong>Sampling:</strong> Sometimes pick lower probabilities for creativity\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "\n",
    "    <script>\n",
    "        function animateBeamPruning() {\n",
    "            const steps = document.querySelectorAll('.beam-step');\n",
    "\n",
    "            steps.forEach((step, stepIndex) => {\n",
    "                setTimeout(() => {\n",
    "                    const candidates = step.querySelectorAll('.candidate');\n",
    "                    candidates.forEach((candidate, candIndex) => {\n",
    "                        setTimeout(() => {\n",
    "                            candidate.style.transform = 'scale(1.1)';\n",
    "                            candidate.style.opacity = '1';\n",
    "                            setTimeout(() => {\n",
    "                                candidate.style.transform = 'scale(1)';\n",
    "                                if (candidate.classList.contains('pruned')) {\n",
    "                                    candidate.style.opacity = '0.4';\n",
    "                                }\n",
    "                            }, 300);\n",
    "                        }, candIndex * 200);\n",
    "                    });\n",
    "                }, stepIndex * 1500);\n",
    "            });\n",
    "        }\n",
    "\n",
    "        function animateTransformerFlow() {\n",
    "            const examples = [\n",
    "                {\n",
    "                    logits: \"Raw Logits: [1.2, -2.1, 3.8, 0.5, -0.8, ...]\",\n",
    "                    words: [\n",
    "                        {word: \"dog\", prob: 45, color: \"#51cf66\"},\n",
    "                        {word: \"cat\", prob: 30, color: \"#ffd43b\"},\n",
    "                        {word: \"bird\", prob: 15, color: \"#ff8787\"},\n",
    "                        {word: \"others\", prob: 10, color: \"#adb5bd\"}\n",
    "                    ],\n",
    "                    selected: \"dog\"\n",
    "                },\n",
    "                {\n",
    "                    logits: \"Raw Logits: [4.1, 0.2, -1.5, 2.3, 1.1, ...]\",\n",
    "                    words: [\n",
    "                        {word: \"sits\", prob: 70, color: \"#51cf66\"},\n",
    "                        {word: \"runs\", prob: 15, color: \"#ffd43b\"},\n",
    "                        {word: \"jumps\", prob: 10, color: \"#ff8787\"},\n",
    "                        {word: \"others\", prob: 5, color: \"#adb5bd\"}\n",
    "                    ],\n",
    "                    selected: \"sits\"\n",
    "                }\n",
    "            ];\n",
    "\n",
    "            const currentExample = examples[Math.floor(Math.random() * examples.length)];\n",
    "\n",
    "            // Update logits\n",
    "            const logitsDisplay = document.querySelector('.flow-step div[style*=\"monospace\"]');\n",
    "            logitsDisplay.innerHTML = currentExample.logits + '<br><small>One number for each word in vocabulary (10,000+ words)</small>';\n",
    "\n",
    "            // Update probabilities\n",
    "            const wordExample = document.querySelector('.word-example');\n",
    "            wordExample.innerHTML = currentExample.words.map(item => `\n",
    "                <div style=\"display: flex; justify-content: space-between; align-items: center; margin: 5px 0;\">\n",
    "                    <span>\"${item.word}\"</span>\n",
    "                    <div class=\"probability-bar\" style=\"width: 150px;\">\n",
    "                        <div class=\"probability-fill\" style=\"width: ${item.prob}%; background: linear-gradient(90deg, ${item.color}, ${item.color});\"></div>\n",
    "                    </div>\n",
    "                    <span>${item.prob}%</span>\n",
    "                </div>\n",
    "            `).join('');\n",
    "\n",
    "            // Update selection\n",
    "            const selection = document.querySelector('.flow-step:last-child div[style*=\"font-size\"]');\n",
    "            selection.innerHTML = `Selected: \"${currentExample.selected}\" ✓`;\n",
    "        }\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Display it\n",
    "HTML(html_content2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "After completing this lab, you will be able to:\n",
    "\n",
    "- Translate a PDF document from German to English\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T16:20:03.885717Z",
     "start_time": "2025-08-20T16:20:03.879816Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#!pip install -U spacy==3.7.2\n",
    "#!pip install -Uqq portalocker==2.7.0\n",
    "#!pip install -qq torchtext==0.14.1\n",
    "#!pip install -Uq nltk==3.8.1\n",
    "\n",
    "#!python -m spacy download de\n",
    "#!python -m spacy download en\n",
    "\n",
    "#!pip install pdfplumber==0.9.0\n",
    "#!pip install fpdf==1.7.2\n",
    "\n",
    "#!wget 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0205EN-SkillsNetwork/Multi30K_de_en_dataloader.py'\n",
    "#!wget 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0201EN-Coursera/transformer.pt'\n",
    "#!wget 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0201EN-Coursera/input_de.pdf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T16:20:06.913780Z",
     "start_time": "2025-08-20T16:20:04.031286Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "# You can also use this section to suppress warnings generated by your code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T16:20:09.736649Z",
     "start_time": "2025-08-20T16:20:06.928752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: Two young, White males are outside near many bushes.\n",
      "German: Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"bentrevett/multi30k\")\n",
    "train_data = dataset['train']\n",
    "val_data = dataset['validation']\n",
    "test_data = dataset['test']\n",
    "\n",
    "# Access the data\n",
    "for example in train_data:\n",
    "    print(f\"English: {example['en']}\")\n",
    "    print(f\"German: {example['de']}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T16:20:09.756681Z",
     "start_time": "2025-08-20T16:20:09.753609Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define special symbols and indices\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T16:20:11.728493Z",
     "start_time": "2025-08-20T16:20:09.825594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building vocabularies...\n",
      "English vocab size: 7964\n",
      "German vocab size: 9762\n",
      "English tensor shape: torch.Size([1, 17])\n",
      "German tensor shape: torch.Size([1, 15])\n",
      "After transpose - English: torch.Size([17, 1])\n",
      "After transpose - German: torch.Size([15, 1])\n",
      "English text: An elderly man sits outside a storefront accompanied by a young boy with a cart.\n",
      "German text: Ein älterer Mann sitzt mit einem Jungen mit einem Wagen vor einer Fassade.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "def build_vocab(sentences, min_freq=2):\n",
    "    \"\"\"Build vocabulary from sentences\"\"\"\n",
    "    counter = Counter()\n",
    "    for sentence in sentences:\n",
    "        counter.update(sentence.split())\n",
    "\n",
    "    vocab = {'<unk>': 0, '<pad>': 1, '<bos>': 2, '<eos>': 3}\n",
    "    for word, freq in counter.items():\n",
    "        if freq >= min_freq:\n",
    "            vocab[word] = len(vocab)\n",
    "\n",
    "    return vocab\n",
    "\n",
    "def text_to_tensor(text, vocab, max_len=None):\n",
    "    \"\"\"Convert text to tensor using vocabulary\"\"\"\n",
    "    tokens = ['<bos>'] + text.split() + ['<eos>']\n",
    "    if max_len:\n",
    "        tokens = tokens[:max_len]\n",
    "\n",
    "    indices = [vocab.get(token, vocab['<unk>']) for token in tokens]\n",
    "    return torch.tensor(indices, dtype=torch.long)\n",
    "\n",
    "def get_translation_dataloaders_hf(batch_size=1, max_len=50):\n",
    "    \"\"\"\n",
    "    Replacement for TorchText's get_translation_dataloaders using Hugging Face Datasets\n",
    "    Returns tensors that can be transposed with .T\n",
    "    \"\"\"\n",
    "    # Load Multi30k dataset\n",
    "    dataset = load_dataset(\"bentrevett/multi30k\")\n",
    "\n",
    "    # Get train and validation datasets\n",
    "    train_dataset = dataset['train']\n",
    "    val_dataset = dataset['validation']\n",
    "\n",
    "    # Build vocabularies (you might want to save/load these)\n",
    "    print(\"Building vocabularies...\")\n",
    "    en_sentences = [item['en'] for item in train_dataset]\n",
    "    de_sentences = [item['de'] for item in train_dataset]\n",
    "\n",
    "    en_vocab = build_vocab(en_sentences)\n",
    "    de_vocab = build_vocab(de_sentences)\n",
    "\n",
    "    print(f\"English vocab size: {len(en_vocab)}\")\n",
    "    print(f\"German vocab size: {len(de_vocab)}\")\n",
    "\n",
    "    def collate_fn(batch):\n",
    "        \"\"\"Custom collate function to convert text to tensors\"\"\"\n",
    "        english_tensors = []\n",
    "        german_tensors = []\n",
    "\n",
    "        # Find max length in batch for padding\n",
    "        max_en_len = max(len(item['en'].split()) + 2 for item in batch)  # +2 for <bos>, <eos>\n",
    "        max_de_len = max(len(item['de'].split()) + 2 for item in batch)\n",
    "\n",
    "        for item in batch:\n",
    "            en_tensor = text_to_tensor(item['en'], en_vocab, max_len)\n",
    "            de_tensor = text_to_tensor(item['de'], de_vocab, max_len)\n",
    "\n",
    "            # Pad to max length in batch\n",
    "            en_padded = torch.nn.functional.pad(en_tensor, (0, max_en_len - len(en_tensor)), value=en_vocab['<pad>'])\n",
    "            de_padded = torch.nn.functional.pad(de_tensor, (0, max_de_len - len(de_tensor)), value=de_vocab['<pad>'])\n",
    "\n",
    "            english_tensors.append(en_padded)\n",
    "            german_tensors.append(de_padded)\n",
    "\n",
    "        # Stack into batch tensors\n",
    "        english_batch = torch.stack(english_tensors)  # [batch_size, seq_len]\n",
    "        german_batch = torch.stack(german_tensors)    # [batch_size, seq_len]\n",
    "\n",
    "        return english_batch, german_batch\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    # Store vocabularies as attributes for later use\n",
    "    train_dataloader.en_vocab = en_vocab\n",
    "    train_dataloader.de_vocab = de_vocab\n",
    "    val_dataloader.en_vocab = en_vocab\n",
    "    val_dataloader.de_vocab = de_vocab\n",
    "\n",
    "    return train_dataloader, val_dataloader\n",
    "\n",
    "train_dataloader, val_dataloader = get_translation_dataloaders_hf(batch_size=1)\n",
    "\n",
    "# Create iterator\n",
    "data_itr = iter(train_dataloader)\n",
    "\n",
    "# Now this will work with tensors\n",
    "english, german = next(data_itr)\n",
    "print(f\"English tensor shape: {english.shape}\")\n",
    "print(f\"German tensor shape: {german.shape}\")\n",
    "\n",
    "# Now you can transpose!\n",
    "german = german.T\n",
    "english = english.T\n",
    "\n",
    "print(f\"After transpose - English: {english.shape}\")\n",
    "print(f\"After transpose - German: {german.shape}\")\n",
    "\n",
    "# Example: decode back to text to verify\n",
    "def decode_tensor(tensor, vocab):\n",
    "    \"\"\"Convert tensor back to text\"\"\"\n",
    "    idx_to_word = {v: k for k, v in vocab.items()}\n",
    "    words = [idx_to_word.get(idx.item(), '<unk>') for idx in tensor.squeeze()]\n",
    "    # Remove padding and special tokens for display\n",
    "    words = [w for w in words if w not in ['<pad>', '<bos>', '<eos>']]\n",
    "    return ' '.join(words)\n",
    "\n",
    "print(f\"English text: {decode_tensor(english, train_dataloader.en_vocab)}\")\n",
    "print(f\"German text: {decode_tensor(german, train_dataloader.de_vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T16:20:12.802943Z",
     "start_time": "2025-08-20T16:20:11.745193Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"bentrevett/multi30k\")\n",
    "train_data = dataset['train']\n",
    "\n",
    "# Create simple iterator\n",
    "data_itr = iter(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T16:20:12.824469Z",
     "start_time": "2025-08-20T16:20:12.817994Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader._SingleProcessDataLoaderIter at 0x166ac3aa0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_itr=iter(train_dataloader)\n",
    "data_itr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T16:20:12.930549Z",
     "start_time": "2025-08-20T16:20:12.864656Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for n in range(1000):\n",
    "    german, english= next(data_itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T16:20:12.941643Z",
     "start_time": "2025-08-20T16:20:12.939477Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "german=german.T\n",
    "english=english.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T16:20:12.965004Z",
     "start_time": "2025-08-20T16:20:12.957207Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def index_to_german(tensor, vocab=None):\n",
    "    \"\"\"Convert German tensor indices back to text\"\"\"\n",
    "    if vocab is None:\n",
    "        raise ValueError(\"Need German vocabulary to decode\")\n",
    "\n",
    "    idx_to_word = {v: k for k, v in vocab.items()}\n",
    "    if tensor.dim() > 1:\n",
    "        # Handle batch dimension\n",
    "        sentences = []\n",
    "        for i in range(tensor.shape[0]):\n",
    "            words = [idx_to_word.get(idx.item(), '<unk>') for idx in tensor[i]]\n",
    "            # Remove special tokens and padding\n",
    "            words = [w for w in words if w not in ['<pad>', '<bos>', '<eos>']]\n",
    "            sentences.append(' '.join(words))\n",
    "        return sentences\n",
    "    else:\n",
    "        words = [idx_to_word.get(idx.item(), '<unk>') for idx in tensor]\n",
    "        words = [w for w in words if w not in ['<pad>', '<bos>', '<eos>']]\n",
    "        return ' '.join(words)\n",
    "\n",
    "def index_to_eng(tensor, vocab=None):\n",
    "    \"\"\"Convert English tensor indices back to text\"\"\"\n",
    "    if vocab is None:\n",
    "        raise ValueError(\"Need English vocabulary to decode\")\n",
    "\n",
    "    idx_to_word = {v: k for k, v in vocab.items()}\n",
    "    if tensor.dim() > 1:\n",
    "        # Handle batch dimension\n",
    "        sentences = []\n",
    "        for i in range(tensor.shape[0]):\n",
    "            words = [idx_to_word.get(idx.item(), '<unk>') for idx in tensor[i]]\n",
    "            # Remove special tokens and padding\n",
    "            words = [w for w in words if w not in ['<pad>', '<bos>', '<eos>']]\n",
    "            sentences.append(' '.join(words))\n",
    "        return sentences\n",
    "    else:\n",
    "        words = [idx_to_word.get(idx.item(), '<unk>') for idx in tensor]\n",
    "        words = [w for w in words if w not in ['<pad>', '<bos>', '<eos>']]\n",
    "        return ' '.join(words)\n",
    "\n",
    "# Global variables to store vocabularies\n",
    "DE_VOCAB = None\n",
    "EN_VOCAB = None\n",
    "\n",
    "def set_global_vocabs(train_dataloader):\n",
    "    \"\"\"Set global vocabularies for easy access\"\"\"\n",
    "    global DE_VOCAB, EN_VOCAB\n",
    "    DE_VOCAB = train_dataloader.de_vocab\n",
    "    EN_VOCAB = train_dataloader.en_vocab\n",
    "\n",
    "def index_to_german_global(tensor):\n",
    "    \"\"\"Convert German tensor to text using global vocab\"\"\"\n",
    "    return index_to_german(tensor, DE_VOCAB)\n",
    "\n",
    "def index_to_eng_global(tensor):\n",
    "    \"\"\"Convert English tensor to text using global vocab\"\"\"\n",
    "    return index_to_eng(tensor, EN_VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T16:20:14.662069Z",
     "start_time": "2025-08-20T16:20:12.989486Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader, _ = get_translation_dataloaders_hf(batch_size=1)\n",
    "set_global_vocabs(train_dataloader)\n",
    "data_itr = iter(train_dataloader)\n",
    "\n",
    "\n",
    "for n in range(10):\n",
    "    german, english = next(data_itr)\n",
    "    print(\"sample {}\".format(n))\n",
    "    print(\"german input\")\n",
    "    print(index_to_german_global(german))\n",
    "    print(\"english target\")\n",
    "    print(index_to_eng_global(english))\n",
    "    print(\"_________\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T16:20:14.679518Z",
     "start_time": "2025-08-20T16:20:14.676378Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T16:20:14.714171Z",
     "start_time": "2025-08-20T16:20:14.711947Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz,device=DEVICE):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T16:20:14.748604Z",
     "start_time": "2025-08-20T16:20:14.744089Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_mask(src, tgt,device=DEVICE):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional encoding\n",
    "The transformer model doesn't have built-in knowledge of the order of tokens in the sequence. To give the model this information, positional encodings are added to the tokens embeddings. These encodings have a fixed pattern based on their position in the sequence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T16:20:14.778430Z",
     "start_time": "2025-08-20T16:20:14.774557Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Add positional information to the input tokens\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token embedding\n",
    "Token embedding, also known as word embedding or word representation, is a way to convert words or tokens from a text corpus into numerical vectors in a continuous vector space. Each unique word or token in the corpus is assigned a fixed-length vector where the numerical values represent various linguistic properties of the word, such as its meaning, context, or relationships with other words.\n",
    "\n",
    "The `TokenEmbedding` class below converts numerical tokens into embeddings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T16:20:14.805403Z",
     "start_time": "2025-08-20T16:20:14.800831Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T16:20:14.827113Z",
     "start_time": "2025-08-20T16:20:14.822900Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers: int,\n",
    "                 num_decoder_layers: int,\n",
    "                 emb_size: int,\n",
    "                 nhead: int,\n",
    "                 src_vocab_size: int,\n",
    "                 tgt_vocab_size: int,\n",
    "                 dim_feedforward: int = 512,\n",
    "                 dropout: float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            emb_size, dropout=dropout)\n",
    "        self.transformer = Transformer(d_model=emb_size,\n",
    "                                       nhead=nhead,\n",
    "                                       num_encoder_layers=num_encoder_layers,\n",
    "                                       num_decoder_layers=num_decoder_layers,\n",
    "                                       dim_feedforward=dim_feedforward,\n",
    "                                       dropout=dropout)\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "\n",
    "    def forward(self,\n",
    "                src: Tensor,\n",
    "                trg: Tensor,\n",
    "                src_mask: Tensor,\n",
    "                tgt_mask: Tensor,\n",
    "                src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor,\n",
    "                memory_key_padding_mask: Tensor):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
    "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "        outs =outs.to(DEVICE)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer.encoder(self.positional_encoding(\n",
    "                            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer.decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "\n",
    "The diagram below illustrates the sequence prediction or inference process.\n",
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0201EN-Coursera/predict_transformers.png\" alt=\"transformer\">\n",
    "The decoder's output is then mapped onto a vocabulary-sized vector using a linear layer. Following this, a softmax function converts these vector scores into probabilities. The highest probability, as determined by the argmax function, provides the index of your predicted word within the translated sequence. This predicted index is fed back into the decoder in conjunction with the initial sequence, setting the stage to determine the subsequent word in the translation. This autoregressive process is demonstrated by the arrow pointing to form the top of the decoder, in green, to the bottom.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T16:20:14.850015Z",
     "start_time": "2025-08-20T16:20:14.847417Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Add this after the get_translation_dataloaders_hf function\n",
    "vocab_transform = {}\n",
    "\n",
    "def create_vocab_transform(train_dataloader):\n",
    "    \"\"\"Create vocab_transform dictionary for compatibility\"\"\"\n",
    "    global vocab_transform\n",
    "    vocab_transform = {\n",
    "        'de': train_dataloader.de_vocab,\n",
    "        'en': train_dataloader.en_vocab\n",
    "    }\n",
    "    return vocab_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T16:20:16.648345Z",
     "start_time": "2025-08-20T16:20:14.869844Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building vocabularies...\n",
      "English vocab size: 7964\n",
      "German vocab size: 9762\n",
      "Source (German) vocab size: 9762\n",
      "Target (English) vocab size: 7964\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, _ = get_translation_dataloaders_hf(batch_size=1)\n",
    "set_global_vocabs(train_dataloader)\n",
    "\n",
    "# Create vocab_transform for compatibility with existing code\n",
    "vocab_transform = create_vocab_transform(train_dataloader)\n",
    "\n",
    "# Now your existing code will work\n",
    "SRC_LANGUAGE = 'de'\n",
    "TGT_LANGUAGE = 'en'\n",
    "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
    "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
    "EMB_SIZE = 512\n",
    "\n",
    "print(f\"Source (German) vocab size: {SRC_VOCAB_SIZE}\")\n",
    "print(f\"Target (English) vocab size: {TGT_VOCAB_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T16:20:16.963916Z",
     "start_time": "2025-08-20T16:20:16.664868Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "SRC_LANGUAGE = 'de'\n",
    "TGT_LANGUAGE = 'en'\n",
    "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
    "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 128\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's will start off with a trained model.For this, load the weights of the transformer model from the file 'transformer.pt'.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T16:20:17.432430Z",
     "start_time": "2025-08-20T16:20:16.984062Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "transformer.load_state_dict(torch.load('transformer.pt', map_location=DEVICE, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"engish target\",index_to_eng(tgt))\n",
    "#print(\"german input\",index_to_german(src))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T18:51:12.527164Z",
     "start_time": "2025-08-20T18:51:11.917295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint expects - German vocab: 19214, English vocab: 10837\n",
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# First, let's check the vocabulary sizes from the checkpoint\n",
    "checkpoint = torch.load('transformer.pt', map_location=DEVICE)\n",
    "src_vocab_size = checkpoint['src_tok_emb.embedding.weight'].shape[0]\n",
    "tgt_vocab_size = checkpoint['tgt_tok_emb.embedding.weight'].shape[0]\n",
    "\n",
    "print(f\"Checkpoint expects - German vocab: {src_vocab_size}, English vocab: {tgt_vocab_size}\")\n",
    "\n",
    "# Create model with the checkpoint's expected vocabulary sizes\n",
    "SRC_VOCAB_SIZE = src_vocab_size  # 19214\n",
    "TGT_VOCAB_SIZE = tgt_vocab_size  # 10837\n",
    "EMB_SIZE = 512\n",
    "\n",
    "# Create the model architecture (you'll need your existing model definition)\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS,\n",
    "                               EMB_SIZE, NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "\n",
    "# Now load the weights\n",
    "transformer.load_state_dict(checkpoint)\n",
    "transformer.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T18:53:06.679219Z",
     "start_time": "2025-08-20T18:53:06.334868Z"
    }
   },
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "def extract_text_pdfplumber(pdf_path):\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T18:53:24.292721Z",
     "start_time": "2025-08-20T18:53:24.271302Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_for_translation(text):\n",
    "    # Split into sentences\n",
    "    sentences = text.split('.')\n",
    "    # Clean each sentence\n",
    "    cleaned_sentences = []\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.strip()\n",
    "        if sentence:  # Skip empty sentences\n",
    "            cleaned_sentences.append(sentence)\n",
    "    return cleaned_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T18:53:36.171512Z",
     "start_time": "2025-08-20T18:53:36.162371Z"
    }
   },
   "outputs": [],
   "source": [
    "def translate_text(text, transformer, src_vocab, tgt_vocab, device):\n",
    "    # Tokenize text using your vocabulary\n",
    "    tokens = ['<bos>'] + text.split() + ['<eos>']\n",
    "    src_indices = [src_vocab.get(token, src_vocab['<unk>']) for token in tokens]\n",
    "    src_tensor = torch.tensor(src_indices).unsqueeze(0).to(device)  # Add batch dimension\n",
    "\n",
    "    # Generate translation using your transformer\n",
    "    with torch.no_grad():\n",
    "        # You'd need to implement the actual inference logic here\n",
    "        # This depends on how your transformer's forward method works\n",
    "        output = transformer.generate(src_tensor)  # This method would need to be implemented\n",
    "\n",
    "    # Convert output indices back to words\n",
    "    tgt_vocab_reverse = {v: k for k, v in tgt_vocab.items()}\n",
    "    translated_words = [tgt_vocab_reverse.get(idx.item(), '<unk>') for idx in output.squeeze()]\n",
    "\n",
    "    return ' '.join(translated_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T18:53:52.200242Z",
     "start_time": "2025-08-20T18:53:52.168475Z"
    }
   },
   "outputs": [],
   "source": [
    "def translate_pdf(pdf_path, transformer, de_vocab, en_vocab, device):\n",
    "    # Extract text\n",
    "    text = extract_text_pdfplumber(pdf_path)\n",
    "\n",
    "    # Split into manageable chunks\n",
    "    sentences = preprocess_for_translation(text)\n",
    "\n",
    "    # Translate each sentence\n",
    "    translated_sentences = []\n",
    "    for sentence in sentences:\n",
    "        if sentence.strip():\n",
    "            try:\n",
    "                translation = translate_text(sentence, transformer, de_vocab, en_vocab, device)\n",
    "                translated_sentences.append(translation)\n",
    "            except Exception as e:\n",
    "                print(f\"Error translating: {sentence[:50]}... Error: {e}\")\n",
    "                translated_sentences.append(f\"[TRANSLATION ERROR: {sentence}]\")\n",
    "\n",
    "    return '\\n'.join(translated_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T18:57:17.538546Z",
     "start_time": "2025-08-20T18:57:17.495697Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Check what methods your transformer has\n",
    "print(dir(transformer))\n",
    "\n",
    "# Or look for methods containing 'translate', 'generate', 'decode':\n",
    "methods = [method for method in dir(transformer) if any(word in method.lower() for word in ['translate', 'generate', 'decode', 'forward'])]\n",
    "print(\"Relevant methods:\", methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T19:07:11.267834Z",
     "start_time": "2025-08-20T19:07:11.237285Z"
    }
   },
   "outputs": [],
   "source": [
    "def translate_sentence_simple(sentence, transformer, de_vocab, en_vocab, device):\n",
    "    try:\n",
    "        # Convert to tokens\n",
    "        src_tokens = ['<bos>'] + sentence.split()[:10] + ['<eos>']\n",
    "        src_indices = [de_vocab.get(token, de_vocab['<unk>']) for token in src_tokens]\n",
    "\n",
    "        # Create tensors with sequence first [seq_len, batch_size]\n",
    "        src_tensor = torch.tensor(src_indices).unsqueeze(1).to(device)  # [seq_len, 1]\n",
    "        tgt_tensor = torch.tensor([en_vocab['<bos>']]).unsqueeze(1).to(device)  # [1, 1]\n",
    "\n",
    "        src_len = src_tensor.size(0)\n",
    "        tgt_len = tgt_tensor.size(0)\n",
    "\n",
    "        # Create masks\n",
    "        src_mask = torch.zeros((src_len, src_len), device=device)\n",
    "        tgt_mask = torch.zeros((tgt_len, tgt_len), device=device)\n",
    "        src_padding_mask = torch.zeros((1, src_len), dtype=torch.bool, device=device)\n",
    "        tgt_padding_mask = torch.zeros((1, tgt_len), dtype=torch.bool, device=device)\n",
    "        memory_key_padding_mask = torch.zeros((1, src_len), dtype=torch.bool, device=device)\n",
    "\n",
    "        # Forward pass\n",
    "        with torch.no_grad():\n",
    "            output = transformer(\n",
    "                src_tensor, tgt_tensor,\n",
    "                src_mask, tgt_mask,\n",
    "                src_padding_mask, tgt_padding_mask,\n",
    "                memory_key_padding_mask\n",
    "            )\n",
    "\n",
    "        # Get the most likely next token\n",
    "        probs = torch.softmax(output[-1, 0], dim=-1)  # Last position, first batch\n",
    "        next_token = torch.argmax(probs).item()\n",
    "\n",
    "        # Convert back to word\n",
    "        en_vocab_rev = {v: k for k, v in en_vocab.items()}\n",
    "        word = en_vocab_rev.get(next_token, '<unk>')\n",
    "\n",
    "        return f\"Predicted next word: {word}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)[:150]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T19:07:14.839904Z",
     "start_time": "2025-08-20T19:07:14.679371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German: Der frühe Morgen bricht an und die ersten Sonnenstrahlen kitzeln san8 mein Gesicht\n",
      "English: Predicted next word: en_6\n",
      "\n",
      "German: Ich atme\n",
      "=ef ein und spüre die frische Morgenlu8 in meinen Lungen\n",
      "English: Predicted next word: en_6\n",
      "\n",
      "German: Mit einem Lächeln auf den Lippen\n",
      "stehe ich auf und beginne den Tag mit voller Energie\n",
      "English: Predicted next word: en_6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Replace in your PDF function:\n",
    "def translate_pdf_simple(pdf_path, transformer, de_vocab, en_vocab, device):\n",
    "    import pdfplumber\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() + \" \"\n",
    "\n",
    "    sentences = text.split('.')\n",
    "\n",
    "    for i, sentence in enumerate(sentences[:3]):\n",
    "        if sentence.strip():\n",
    "            print(f\"German: {sentence.strip()}\")\n",
    "            translation = translate_sentence_simple(sentence.strip(), transformer, de_vocab, en_vocab, device)\n",
    "            print(f\"English: {translation}\")\n",
    "            print()\n",
    "\n",
    "# Use it:\n",
    "# Create vocabularies with the exact sizes the model expects\n",
    "def create_dummy_vocab(size, prefix=\"word\"):\n",
    "    vocab = {'<unk>': 0, '<pad>': 1, '<bos>': 2, '<eos>': 3}\n",
    "    for i in range(4, size):\n",
    "        vocab[f\"{prefix}_{i}\"] = i\n",
    "    return vocab\n",
    "\n",
    "# Create the vocabularies\n",
    "de_vocab = create_dummy_vocab(19214, \"de\")  # German vocab\n",
    "en_vocab = create_dummy_vocab(10837, \"en\")  # English vocab\n",
    "\n",
    "# Now you can use them\n",
    "translate_pdf_simple('input_de.pdf', transformer, de_vocab, en_vocab, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: Hallo Welt, wie geht es dir?\n",
      "Input IDs: tensor([[11918,   401,     2,   107,   652,    65,   600,    31,     0]])\n",
      "Output IDs: tensor([[58100, 16816,     2,   360,     2,   406,    48,    41,    31,     0]])\n",
      "Output shape: torch.Size([1, 10])\n",
      "Translated text: Hello, world, how are you?\n",
      "Translation 1: Hello, world, how are you?\n",
      "Translation 2: Hello world, how are you?\n",
      "Translation 3: Hello, world. How are you?\n"
     ]
    }
   ],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "model = MarianMTModel.from_pretrained(\"Helsinki-NLP/opus-mt-de-en\")\n",
    "tokenizer = MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-de-en\")\n",
    "\n",
    "# Input\n",
    "text = \"Hallo Welt, wie geht es dir?\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "print(f\"Input text: {text}\")\n",
    "print(f\"Input IDs: {inputs['input_ids']}\")\n",
    "\n",
    "# Generate translation\n",
    "outputs = model.generate(\n",
    "    inputs['input_ids'],\n",
    "    num_beams=5,\n",
    "    max_length=50,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "print(f\"Output IDs: {outputs}\")\n",
    "print(f\"Output shape: {outputs.shape}\")\n",
    "\n",
    "# Decode back to text\n",
    "translated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(f\"Translated text: {translated_text}\")\n",
    "\n",
    "# Return multiple sequences\n",
    "outputs = model.generate(\n",
    "    inputs['input_ids'],\n",
    "    num_beams=5,\n",
    "    num_return_sequences=3,  # Get top 3 beam results\n",
    "    max_length=50,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "# Decode all sequences\n",
    "for i, output in enumerate(outputs):\n",
    "    translated = tokenizer.decode(output, skip_special_tokens=True)\n",
    "    print(f\"Translation {i+1}: {translated}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Loading Hugging Face German-English translation model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded successfully!\n",
      "\n",
      "======================================================================\n",
      "SENTENCE 1: Der alte Mann der Straße gibt dem Kind einen Ball\n",
      "======================================================================\n",
      "Input IDs: tensor([[ 119, 4712, 1155,    9, 3766,  297,   57, 2821,  106, 5454,    0]])\n",
      "\n",
      "🔍 GREEDY DECODING:\n",
      "   The old man on the street gives the child a ball\n",
      "\n",
      "🌟 BEAM SEARCH (k=5, best result):\n",
      "   The old man on the street gives the child a ball\n",
      "\n",
      "🎯 BEAM SEARCH (top 3 candidates):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1. The old man on the street gives the child a ball\n",
      "   2. The old man on the street gives the kid a ball\n",
      "   3. The old man in the street gives the child a ball\n",
      "\n",
      "🔄 BEAM SIZE COMPARISON:\n",
      "   Beam size 1: The old man on the street gives the child a ball\n",
      "   Beam size 3: The old man on the street gives the child a ball\n",
      "   Beam size 5: The old man on the street gives the child a ball\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Beam size 8: The old man on the street gives the child a ball\n",
      "\n",
      "📊 DETAILED TOKEN ANALYSIS:\n",
      "   Input tokens:   ['▁Der', '▁alte', '▁Mann', '▁der', '▁Straße', '▁gibt', '▁dem', '▁Kind', '▁einen', '▁Ball', '</s>']\n",
      "   Greedy tokens:  ['<pad>', '▁The', '▁old', '▁man', '▁on', '▁the', '▁street', '▁gives', '▁the', '▁child', '▁a', '▁ball', '</s>']\n",
      "   Beam tokens:    ['<pad>', '▁The', '▁old', '▁man', '▁on', '▁the', '▁street', '▁gives', '▁the', '▁child', '▁a', '▁ball', '</s>']\n",
      "\n",
      "======================================================================\n",
      "SENTENCE 2: Der Mann sieht den Hund mit dem Fernglas\n",
      "======================================================================\n",
      "Input IDs: tensor([[ 119, 1155, 2381,   25, 9162,   30,   57, 6015, 9817,    0]])\n",
      "\n",
      "🔍 GREEDY DECODING:\n",
      "   The man sees the dog with the binoculars\n",
      "\n",
      "🌟 BEAM SEARCH (k=5, best result):\n",
      "   The man sees the dog with the binoculars\n",
      "\n",
      "🎯 BEAM SEARCH (top 3 candidates):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1. The man sees the dog with the binoculars\n",
      "   2. The man sees the dog with binoculars\n",
      "   3. The man sees the dog with his binoculars\n",
      "\n",
      "🔄 BEAM SIZE COMPARISON:\n",
      "   Beam size 1: The man sees the dog with the binoculars\n",
      "   Beam size 3: The man sees the dog with the binoculars\n",
      "   Beam size 5: The man sees the dog with the binoculars\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Beam size 8: The man sees the dog with the binoculars\n",
      "\n",
      "======================================================================\n",
      "SENTENCE 3: Das kann man nicht machen\n",
      "======================================================================\n",
      "Input IDs: tensor([[103, 134, 175,  51, 522,   0]])\n",
      "\n",
      "🔍 GREEDY DECODING:\n",
      "   You can't do that\n",
      "\n",
      "🌟 BEAM SEARCH (k=5, best result):\n",
      "   You can't do that\n",
      "\n",
      "🎯 BEAM SEARCH (top 3 candidates):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1. You can't do that\n",
      "   2. You can't do that.\n",
      "   3. You can't do this.\n",
      "\n",
      "🔄 BEAM SIZE COMPARISON:\n",
      "   Beam size 1: You can't do that\n",
      "   Beam size 3: You can't do that\n",
      "   Beam size 5: You can't do that\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Beam size 8: You can't do that\n",
      "\n",
      "======================================================================\n",
      "SENTENCE 4: Maria gab Anna das Buch, weil sie es brauchte\n",
      "======================================================================\n",
      "Input IDs: tensor([[ 2719,  1647,  6323,    44,  1817,     2,   765,    76,    65, 27088,\n",
      "             0]])\n",
      "\n",
      "🔍 GREEDY DECODING:\n",
      "   Mary gave Anna the book because she needed it\n",
      "\n",
      "🌟 BEAM SEARCH (k=5, best result):\n",
      "   Mary gave Anna the book because she needed it\n",
      "\n",
      "🎯 BEAM SEARCH (top 3 candidates):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1. Mary gave Anna the book because she needed it\n",
      "   2. Mary gave the book to Anna because she needed it\n",
      "   3. Mary gave Anna the book because she needed it.\n",
      "\n",
      "🔄 BEAM SIZE COMPARISON:\n",
      "   Beam size 1: Mary gave Anna the book because she needed it\n",
      "   Beam size 3: Mary gave Anna the book because she needed it\n",
      "   Beam size 5: Mary gave Anna the book because she needed it\n",
      "   Beam size 8: Mary gave Anna the book because she needed it\n",
      "\n",
      "🎲 SAMPLING METHODS COMPARISON\n",
      "==================================================\n",
      "Input: Der alte Mann der Straße gibt dem Kind einen Ball\n",
      "\n",
      "🔧 Beam Search (k=5):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   The old man on the street gives the child a ball\n",
      "\n",
      "🔧 Top-k Sampling (k=50):\n",
      "   Sample 1: The old man on the street gives the child a ball\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sample 2: The old man of the street gives the child a ball\n",
      "\n",
      "🔧 Top-p Sampling (p=0.9):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sample 1: The old man in the street gives the kid a ball\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sample 2: The old man of the street gives a ball to the kid\n",
      "\n",
      "🔧 Low Temperature (0.3):\n",
      "   Sample 1: The old man on the street gives the child a ball\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sample 2: The old man on the street gives the child a ball\n",
      "\n",
      "🔧 High Temperature (1.5):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sample 1: Creating A Bump to Tide with this Road, Old Man Heds\n",
      "   Sample 2: The old guy on Araq road, going all the way across a beautiful old town in a girl like that, hands a ball over a movie when people come across the streets they tell around the world\n",
      "\n",
      "🎉 Translation comparison complete!\n",
      "💡 Notice how beam search explores different interpretations of ambiguous sentences!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (run this first if needed)\n",
    "# !pip install transformers torch sentencepiece\n",
    "\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "import torch\n",
    "\n",
    "# Load pre-trained German to English translation model\n",
    "print(\"📥 Loading Hugging Face German-English translation model...\")\n",
    "model_name = \"Helsinki-NLP/opus-mt-de-en\"\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "print(\"✅ Model loaded successfully!\")\n",
    "\n",
    "# Interesting ambiguous German sentences for beam search\n",
    "sentences = [\n",
    "    \"Der alte Mann der Straße gibt dem Kind einen Ball\",\n",
    "    \"Der Mann sieht den Hund mit dem Fernglas\", \n",
    "    \"Das kann man nicht machen\",\n",
    "    \"Maria gab Anna das Buch, weil sie es brauchte\"\n",
    "]\n",
    "\n",
    "for i, text in enumerate(sentences, 1):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"SENTENCE {i}: {text}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    print(f\"Input IDs: {inputs['input_ids']}\")\n",
    "    \n",
    "    # 1. Greedy decoding (baseline)\n",
    "    print(f\"\\n🔍 GREEDY DECODING:\")\n",
    "    greedy_output = model.generate(\n",
    "        inputs['input_ids'],\n",
    "        max_length=50,\n",
    "        num_beams=1,  # Greedy\n",
    "        early_stopping=True\n",
    "    )\n",
    "    greedy_text = tokenizer.decode(greedy_output[0], skip_special_tokens=True)\n",
    "    print(f\"   {greedy_text}\")\n",
    "    \n",
    "    # 2. Beam search - single best\n",
    "    print(f\"\\n🌟 BEAM SEARCH (k=5, best result):\")\n",
    "    beam_output = model.generate(\n",
    "        inputs['input_ids'],\n",
    "        max_length=50,\n",
    "        num_beams=5,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    beam_text = tokenizer.decode(beam_output[0], skip_special_tokens=True)\n",
    "    print(f\"   {beam_text}\")\n",
    "    \n",
    "    # 3. Beam search - multiple candidates\n",
    "    print(f\"\\n🎯 BEAM SEARCH (top 3 candidates):\")\n",
    "    multiple_outputs = model.generate(\n",
    "        inputs['input_ids'],\n",
    "        max_length=50,\n",
    "        num_beams=5,\n",
    "        num_return_sequences=3,  # Return top 3\n",
    "        early_stopping=True\n",
    "    )\n",
    "    \n",
    "    for j, output in enumerate(multiple_outputs, 1):\n",
    "        candidate_text = tokenizer.decode(output, skip_special_tokens=True)\n",
    "        print(f\"   {j}. {candidate_text}\")\n",
    "    \n",
    "    # 4. Different beam sizes comparison\n",
    "    print(f\"\\n🔄 BEAM SIZE COMPARISON:\")\n",
    "    for beam_size in [1, 3, 5, 8]:\n",
    "        beam_result = model.generate(\n",
    "            inputs['input_ids'],\n",
    "            max_length=50,\n",
    "            num_beams=beam_size,\n",
    "            early_stopping=True\n",
    "        )\n",
    "        result_text = tokenizer.decode(beam_result[0], skip_special_tokens=True)\n",
    "        print(f\"   Beam size {beam_size}: {result_text}\")\n",
    "    \n",
    "    if i == 1:  # Show detailed analysis for first sentence only\n",
    "        print(f\"\\n📊 DETAILED TOKEN ANALYSIS:\")\n",
    "        print(f\"   Input tokens:   {tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])}\")\n",
    "        print(f\"   Greedy tokens:  {tokenizer.convert_ids_to_tokens(greedy_output[0])}\")\n",
    "        print(f\"   Beam tokens:    {tokenizer.convert_ids_to_tokens(beam_output[0])}\")\n",
    "\n",
    "# Bonus: Compare with sampling methods for the most ambiguous sentence\n",
    "print(f\"\\n{'🎲 SAMPLING METHODS COMPARISON'}\")\n",
    "print(f\"{'='*50}\")\n",
    "text = \"Der alte Mann der Straße gibt dem Kind einen Ball\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "print(f\"Input: {text}\\n\")\n",
    "\n",
    "torch.manual_seed(42)  # For reproducibility\n",
    "\n",
    "sampling_methods = [\n",
    "    {\"name\": \"Beam Search (k=5)\", \"num_beams\": 5, \"do_sample\": False},\n",
    "    {\"name\": \"Top-k Sampling (k=50)\", \"do_sample\": True, \"top_k\": 50, \"temperature\": 0.8, \"num_beams\": 1},\n",
    "    {\"name\": \"Top-p Sampling (p=0.9)\", \"do_sample\": True, \"top_p\": 0.9, \"temperature\": 0.8, \"num_beams\": 1},\n",
    "    {\"name\": \"Low Temperature (0.3)\", \"do_sample\": True, \"temperature\": 0.3, \"num_beams\": 1},\n",
    "    {\"name\": \"High Temperature (1.5)\", \"do_sample\": True, \"temperature\": 1.5, \"num_beams\": 1}\n",
    "]\n",
    "\n",
    "for method in sampling_methods:\n",
    "    print(f\"🔧 {method['name']}:\")\n",
    "    method_params = {k: v for k, v in method.items() if k != 'name'}\n",
    "    \n",
    "    # Generate 2 samples to show variation\n",
    "    num_samples = 2 if method['name'] != \"Beam Search (k=5)\" else 1\n",
    "    for i in range(num_samples):\n",
    "        output = model.generate(\n",
    "            inputs['input_ids'],\n",
    "            max_length=50,\n",
    "            early_stopping=True,\n",
    "            **method_params\n",
    "        )\n",
    "        result = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        sample_text = f\"Sample {i+1}: \" if num_samples > 1 else \"\"\n",
    "        print(f\"   {sample_text}{result}\")\n",
    "    print()\n",
    "\n",
    "print(\"🎉 Translation comparison complete!\")\n",
    "print(\"💡 Notice how beam search explores different interpretations of ambiguous sentences!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T19:11:49.256222Z",
     "start_time": "2025-08-20T19:11:49.215636Z"
    }
   },
   "outputs": [],
   "source": [
    "def greedy_decode(transformer, src_tensor, src_mask, en_vocab, device, max_len=20):\n",
    "    \"\"\"Greedy decoding - always pick the most likely next word\"\"\"\n",
    "    generated_tokens = [en_vocab['<bos>']]\n",
    "\n",
    "    for i in range(max_len):\n",
    "        tgt_tensor = torch.tensor(generated_tokens).unsqueeze(1).to(device)\n",
    "        tgt_len = tgt_tensor.size(0)\n",
    "        src_len = src_tensor.size(0)\n",
    "\n",
    "        # Create proper masks\n",
    "        src_mask = torch.zeros((src_len, src_len), device=device)\n",
    "        tgt_mask = torch.zeros((tgt_len, tgt_len), device=device)  # Fixed: use tgt_len\n",
    "        src_padding_mask = torch.zeros((1, src_len), dtype=torch.bool, device=device)\n",
    "        tgt_padding_mask = torch.zeros((1, tgt_len), dtype=torch.bool, device=device)\n",
    "        memory_key_padding_mask = torch.zeros((1, src_len), dtype=torch.bool, device=device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = transformer(src_tensor, tgt_tensor, src_mask, tgt_mask,\n",
    "                               src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "\n",
    "        # Greedy: pick the most likely token\n",
    "        probs = torch.softmax(output[-1, 0], dim=-1)\n",
    "        next_token = torch.argmax(probs).item()\n",
    "\n",
    "        if next_token == en_vocab['<eos>']:\n",
    "            break\n",
    "\n",
    "        generated_tokens.append(next_token)\n",
    "\n",
    "    return generated_tokens[1:]  # Remove <bos>\n",
    "\n",
    "def beam_search(transformer, src_tensor, src_mask, en_vocab, device, beam_size=3, max_len=20):\n",
    "    \"\"\"Beam search - keep track of top K sequences\"\"\"\n",
    "    beams = [([en_vocab['<bos>']], 0.0)]\n",
    "\n",
    "    for i in range(max_len):\n",
    "        candidates = []\n",
    "\n",
    "        for sequence, score in beams:\n",
    "            if sequence[-1] == en_vocab['<eos>']:\n",
    "                candidates.append((sequence, score))\n",
    "                continue\n",
    "\n",
    "            tgt_tensor = torch.tensor(sequence).unsqueeze(1).to(device)\n",
    "            tgt_len = tgt_tensor.size(0)\n",
    "            src_len = src_tensor.size(0)\n",
    "\n",
    "            # Create proper masks\n",
    "            src_mask_local = torch.zeros((src_len, src_len), device=device)\n",
    "            tgt_mask = torch.zeros((tgt_len, tgt_len), device=device)  # Fixed\n",
    "            src_padding_mask = torch.zeros((1, src_len), dtype=torch.bool, device=device)\n",
    "            tgt_padding_mask = torch.zeros((1, tgt_len), dtype=torch.bool, device=device)\n",
    "            memory_key_padding_mask = torch.zeros((1, src_len), dtype=torch.bool, device=device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = transformer(src_tensor, tgt_tensor, src_mask_local, tgt_mask,\n",
    "                                   src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "\n",
    "            # Get top beam_size tokens\n",
    "            log_probs = torch.log_softmax(output[-1, 0], dim=-1)\n",
    "            top_probs, top_indices = torch.topk(log_probs, beam_size)\n",
    "\n",
    "            for prob, idx in zip(top_probs, top_indices):\n",
    "                new_sequence = sequence + [idx.item()]\n",
    "                new_score = score + prob.item()\n",
    "                candidates.append((new_sequence, new_score))\n",
    "\n",
    "        # Keep only top beam_size sequences\n",
    "        beams = sorted(candidates, key=lambda x: x[1], reverse=True)[:beam_size]\n",
    "\n",
    "        # Check if all beams ended\n",
    "        if all(seq[-1] == en_vocab['<eos>'] for seq, _ in beams):\n",
    "            break\n",
    "\n",
    "    best_sequence, best_score = beams[0]\n",
    "    return best_sequence[1:]  # Remove <bos>\n",
    "\n",
    "def compare_decoding_methods(sentence, transformer, de_vocab, en_vocab, device):\n",
    "    \"\"\"Compare greedy vs beam search for a sentence\"\"\"\n",
    "    try:\n",
    "        # Prepare source\n",
    "        src_tokens = ['<bos>'] + sentence.split()[:8] + ['<eos>']\n",
    "        src_indices = [de_vocab.get(token, de_vocab['<unk>']) for token in src_tokens]\n",
    "        src_tensor = torch.tensor(src_indices).unsqueeze(1).to(device)\n",
    "        src_mask = None  # Let the functions create their own masks\n",
    "\n",
    "        print(f\"German: {sentence}\")\n",
    "\n",
    "        # Greedy decoding\n",
    "        greedy_tokens = greedy_decode(transformer, src_tensor, src_mask, en_vocab, device)\n",
    "        en_vocab_rev = {v: k for k, v in en_vocab.items()}\n",
    "        greedy_words = [en_vocab_rev.get(token, f'token_{token}') for token in greedy_tokens]\n",
    "        print(f\"Greedy:     {' '.join(greedy_words)}\")\n",
    "\n",
    "        # Beam search\n",
    "        beam_tokens = beam_search(transformer, src_tensor, src_mask, en_vocab, device, beam_size=3)\n",
    "        beam_words = [en_vocab_rev.get(token, f'token_{token}') for token in beam_tokens]\n",
    "        print(f\"Beam(k=3):  {' '.join(beam_words)}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)[:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T19:11:54.834571Z",
     "start_time": "2025-08-20T19:11:52.748896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German: Der frühe Morgen bricht an\n",
      "Greedy:     en_6 en_193 en_966 en_10 en_199 en_26 en_1365 en_5\n",
      "Beam(k=3):  en_6 en_193 en_966 en_14 en_26 en_1424 <eos>\n",
      "--------------------------------------------------\n",
      "German: Ich gehe zur Schule\n",
      "Greedy:     en_6 en_193 en_966 en_10 en_199 en_26 en_1365 en_5\n",
      "Beam(k=3):  en_6 en_193 en_966 en_14 en_26 en_1424 <eos>\n",
      "--------------------------------------------------\n",
      "German: Das Wetter ist schön\n",
      "Greedy:     en_6 en_193 en_966 en_10 en_199 en_26 en_1365 en_5\n",
      "Beam(k=3):  en_6 en_193 en_966 en_14 en_26 en_1424 <eos>\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Usage:\n",
    "sentences = [\n",
    "    \"Der frühe Morgen bricht an\",\n",
    "    \"Ich gehe zur Schule\",\n",
    "    \"Das Wetter ist schön\"\n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "    compare_decoding_methods(sentence, transformer, de_vocab, en_vocab, DEVICE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "prev_pub_hash": "f583ab330d392f3fbc803e1d84830f575a94e0d7cc0f8b3af49ded45fd51cc14"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
